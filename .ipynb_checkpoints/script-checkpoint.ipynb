{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/worldmodels/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import cma\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "from keras.layers import concatenate, Input, LSTM, Dense, Conv2D, Conv2DTranspose, Lambda, Reshape, Flatten, Embedding\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = (64,64,3) #(28,28,1)#\n",
    "lstm_hidden_units = 256\n",
    "gaussian_mixtures = 5\n",
    "z_dim = 32\n",
    "discrete_dim = 0\n",
    "action_dim = 3\n",
    "NPARAMS = (z_dim + lstm_hidden_units + 1) * action_dim\n",
    "\n",
    "vae_epochs = 1\n",
    "mdn_epochs = 20\n",
    "     \n",
    "NPOPULATION = 16   \n",
    "MAX_ITERATION = 100 \n",
    "AGENT_ROLLOUTS = 1 #--num_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random_action(t, current_action):\n",
    "#     a = env.action_space.sample()\n",
    "#     return a\n",
    "    if t < 60:\n",
    "        return np.array([0,1,0])\n",
    "    \n",
    "    if t % 5 > 0:\n",
    "        return current_action\n",
    "\n",
    "    rn = random.randint(0,9)\n",
    "    if rn in [0]:\n",
    "        return np.array([0,0,0])\n",
    "    if rn in [1,2,3,4]:\n",
    "        return np.array([0,1,0])\n",
    "    if rn in [5,6,7]:\n",
    "        return np.array([-1,0,0])\n",
    "    if rn in [8]:\n",
    "        return np.array([1,0,0])\n",
    "    if rn in [9]:\n",
    "        return np.array([0,0,1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = []\n",
    "action_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = np.load('./archive/data/obs_data.npy')\n",
    "action_data = np.load('./archive/data/action_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Episode 0 finished after 301 timesteps\n",
      "Dataset contains 300 observations\n",
      "-----\n",
      "Episode 1 finished after 301 timesteps\n",
      "Dataset contains 600 observations\n",
      "-----\n",
      "Episode 2 finished after 301 timesteps\n",
      "Dataset contains 900 observations\n",
      "-----\n",
      "Episode 3 finished after 301 timesteps\n",
      "Dataset contains 1200 observations\n",
      "-----\n",
      "Episode 4 finished after 301 timesteps\n",
      "Dataset contains 1500 observations\n",
      "-----\n",
      "Episode 5 finished after 301 timesteps\n",
      "Dataset contains 1800 observations\n",
      "-----\n",
      "Episode 6 finished after 301 timesteps\n",
      "Dataset contains 2100 observations\n",
      "-----\n",
      "Episode 7 finished after 301 timesteps\n",
      "Dataset contains 2400 observations\n",
      "-----\n",
      "Episode 8 finished after 301 timesteps\n",
      "Dataset contains 2700 observations\n",
      "-----\n",
      "Episode 9 finished after 301 timesteps\n",
      "Dataset contains 3000 observations\n",
      "-----\n",
      "Episode 10 finished after 301 timesteps\n",
      "Dataset contains 3300 observations\n",
      "-----\n",
      "Episode 11 finished after 301 timesteps\n",
      "Dataset contains 3600 observations\n",
      "-----\n",
      "Episode 12 finished after 301 timesteps\n",
      "Dataset contains 3900 observations\n",
      "-----\n",
      "Episode 13 finished after 301 timesteps\n",
      "Dataset contains 4200 observations\n",
      "-----\n",
      "Episode 14 finished after 301 timesteps\n",
      "Dataset contains 4500 observations\n",
      "-----\n",
      "Episode 15 finished after 301 timesteps\n",
      "Dataset contains 4800 observations\n",
      "-----\n",
      "Episode 16 finished after 301 timesteps\n",
      "Dataset contains 5100 observations\n",
      "-----\n",
      "Episode 17 finished after 301 timesteps\n",
      "Dataset contains 5400 observations\n",
      "-----\n",
      "Episode 18 finished after 301 timesteps\n",
      "Dataset contains 5700 observations\n",
      "-----\n",
      "Episode 19 finished after 301 timesteps\n",
      "Dataset contains 6000 observations\n",
      "-----\n",
      "Episode 20 finished after 301 timesteps\n",
      "Dataset contains 6300 observations\n",
      "-----\n",
      "Episode 21 finished after 301 timesteps\n",
      "Dataset contains 6600 observations\n",
      "-----\n",
      "Episode 22 finished after 301 timesteps\n",
      "Dataset contains 6900 observations\n",
      "-----\n",
      "Episode 23 finished after 301 timesteps\n",
      "Dataset contains 7200 observations\n",
      "-----\n",
      "Episode 24 finished after 301 timesteps\n",
      "Dataset contains 7500 observations\n",
      "-----\n",
      "Episode 25 finished after 301 timesteps\n",
      "Dataset contains 7800 observations\n",
      "-----\n",
      "Episode 26 finished after 301 timesteps\n",
      "Dataset contains 8100 observations\n",
      "-----\n",
      "Episode 27 finished after 301 timesteps\n",
      "Dataset contains 8400 observations\n",
      "-----\n",
      "Episode 28 finished after 301 timesteps\n",
      "Dataset contains 8700 observations\n",
      "-----\n",
      "Episode 29 finished after 301 timesteps\n",
      "Dataset contains 9000 observations\n",
      "-----\n",
      "Episode 30 finished after 301 timesteps\n",
      "Dataset contains 9300 observations\n",
      "-----\n",
      "Episode 31 finished after 301 timesteps\n",
      "Dataset contains 9600 observations\n",
      "-----\n",
      "Episode 32 finished after 301 timesteps\n",
      "Dataset contains 9900 observations\n",
      "-----\n",
      "Episode 33 finished after 301 timesteps\n",
      "Dataset contains 10200 observations\n",
      "-----\n",
      "Episode 34 finished after 301 timesteps\n",
      "Dataset contains 10500 observations\n",
      "-----\n",
      "Episode 35 finished after 301 timesteps\n",
      "Dataset contains 10800 observations\n",
      "-----\n",
      "Episode 36 finished after 301 timesteps\n",
      "Dataset contains 11100 observations\n",
      "-----\n",
      "Episode 37 finished after 301 timesteps\n",
      "Dataset contains 11400 observations\n",
      "-----\n",
      "Episode 38 finished after 301 timesteps\n",
      "Dataset contains 11700 observations\n",
      "-----\n",
      "Episode 39 finished after 301 timesteps\n",
      "Dataset contains 12000 observations\n",
      "-----\n",
      "Episode 40 finished after 301 timesteps\n",
      "Dataset contains 12300 observations\n",
      "-----\n",
      "Episode 41 finished after 301 timesteps\n",
      "Dataset contains 12600 observations\n",
      "-----\n",
      "Episode 42 finished after 301 timesteps\n",
      "Dataset contains 12900 observations\n",
      "-----\n",
      "Episode 43 finished after 301 timesteps\n",
      "Dataset contains 13200 observations\n",
      "-----\n",
      "Episode 44 finished after 301 timesteps\n",
      "Dataset contains 13500 observations\n",
      "-----\n",
      "Episode 45 finished after 301 timesteps\n",
      "Dataset contains 13800 observations\n",
      "-----\n",
      "Episode 46 finished after 301 timesteps\n",
      "Dataset contains 14100 observations\n",
      "-----\n",
      "Episode 47 finished after 301 timesteps\n",
      "Dataset contains 14400 observations\n",
      "-----\n",
      "Episode 48 finished after 301 timesteps\n",
      "Dataset contains 14700 observations\n",
      "-----\n",
      "Episode 49 finished after 301 timesteps\n",
      "Dataset contains 15000 observations\n",
      "-----\n",
      "Episode 50 finished after 301 timesteps\n",
      "Dataset contains 15300 observations\n",
      "-----\n",
      "Episode 51 finished after 301 timesteps\n",
      "Dataset contains 15600 observations\n",
      "-----\n",
      "Episode 52 finished after 301 timesteps\n",
      "Dataset contains 15900 observations\n",
      "-----\n",
      "Episode 53 finished after 301 timesteps\n",
      "Dataset contains 16200 observations\n",
      "-----\n",
      "Episode 54 finished after 301 timesteps\n",
      "Dataset contains 16500 observations\n",
      "-----\n",
      "Episode 55 finished after 301 timesteps\n",
      "Dataset contains 16800 observations\n",
      "-----\n",
      "Episode 56 finished after 301 timesteps\n",
      "Dataset contains 17100 observations\n",
      "-----\n",
      "Episode 57 finished after 301 timesteps\n",
      "Dataset contains 17400 observations\n",
      "-----\n",
      "Episode 58 finished after 301 timesteps\n",
      "Dataset contains 17700 observations\n",
      "-----\n",
      "Episode 59 finished after 301 timesteps\n",
      "Dataset contains 18000 observations\n",
      "-----\n",
      "Episode 60 finished after 301 timesteps\n",
      "Dataset contains 18300 observations\n",
      "-----\n",
      "Episode 61 finished after 301 timesteps\n",
      "Dataset contains 18600 observations\n",
      "-----\n",
      "Episode 62 finished after 301 timesteps\n",
      "Dataset contains 18900 observations\n",
      "-----\n",
      "Episode 63 finished after 301 timesteps\n",
      "Dataset contains 19200 observations\n",
      "-----\n",
      "Episode 64 finished after 301 timesteps\n",
      "Dataset contains 19500 observations\n",
      "-----\n",
      "Episode 65 finished after 301 timesteps\n",
      "Dataset contains 19800 observations\n",
      "-----\n",
      "Episode 66 finished after 301 timesteps\n",
      "Dataset contains 20100 observations\n",
      "-----\n",
      "Episode 67 finished after 301 timesteps\n",
      "Dataset contains 20400 observations\n",
      "-----\n",
      "Episode 68 finished after 301 timesteps\n",
      "Dataset contains 20700 observations\n",
      "-----\n",
      "Episode 69 finished after 301 timesteps\n",
      "Dataset contains 21000 observations\n",
      "-----\n",
      "Episode 70 finished after 301 timesteps\n",
      "Dataset contains 21300 observations\n",
      "-----\n",
      "Episode 71 finished after 301 timesteps\n",
      "Dataset contains 21600 observations\n",
      "-----\n",
      "Episode 72 finished after 301 timesteps\n",
      "Dataset contains 21900 observations\n",
      "-----\n",
      "Episode 73 finished after 301 timesteps\n",
      "Dataset contains 22200 observations\n",
      "-----\n",
      "Episode 74 finished after 301 timesteps\n",
      "Dataset contains 22500 observations\n",
      "-----\n",
      "Episode 75 finished after 301 timesteps\n",
      "Dataset contains 22800 observations\n",
      "-----\n",
      "Episode 76 finished after 301 timesteps\n",
      "Dataset contains 23100 observations\n",
      "-----\n",
      "Episode 77 finished after 301 timesteps\n",
      "Dataset contains 23400 observations\n",
      "-----\n",
      "Episode 78 finished after 301 timesteps\n",
      "Dataset contains 23700 observations\n",
      "-----\n",
      "Episode 79 finished after 301 timesteps\n",
      "Dataset contains 24000 observations\n",
      "-----\n",
      "Episode 80 finished after 301 timesteps\n",
      "Dataset contains 24300 observations\n",
      "-----\n",
      "Episode 81 finished after 301 timesteps\n",
      "Dataset contains 24600 observations\n",
      "-----\n",
      "Episode 82 finished after 301 timesteps\n",
      "Dataset contains 24900 observations\n",
      "-----\n",
      "Episode 83 finished after 301 timesteps\n",
      "Dataset contains 25200 observations\n",
      "-----\n",
      "Episode 84 finished after 301 timesteps\n",
      "Dataset contains 25500 observations\n",
      "-----\n",
      "Episode 85 finished after 301 timesteps\n",
      "Dataset contains 25800 observations\n",
      "-----\n",
      "Episode 86 finished after 301 timesteps\n",
      "Dataset contains 26100 observations\n",
      "-----\n",
      "Episode 87 finished after 301 timesteps\n",
      "Dataset contains 26400 observations\n",
      "-----\n",
      "Episode 88 finished after 301 timesteps\n",
      "Dataset contains 26700 observations\n",
      "-----\n",
      "Episode 89 finished after 301 timesteps\n",
      "Dataset contains 27000 observations\n",
      "-----\n",
      "Episode 90 finished after 301 timesteps\n",
      "Dataset contains 27300 observations\n",
      "-----\n",
      "Episode 91 finished after 301 timesteps\n",
      "Dataset contains 27600 observations\n",
      "-----\n",
      "Episode 92 finished after 301 timesteps\n",
      "Dataset contains 27900 observations\n",
      "-----\n",
      "Episode 93 finished after 301 timesteps\n",
      "Dataset contains 28200 observations\n",
      "-----\n",
      "Episode 94 finished after 301 timesteps\n",
      "Dataset contains 28500 observations\n",
      "-----\n",
      "Episode 95 finished after 301 timesteps\n",
      "Dataset contains 28800 observations\n",
      "-----\n",
      "Episode 96 finished after 301 timesteps\n",
      "Dataset contains 29100 observations\n",
      "-----\n",
      "Episode 97 finished after 301 timesteps\n",
      "Dataset contains 29400 observations\n",
      "-----\n",
      "Episode 98 finished after 301 timesteps\n",
      "Dataset contains 29700 observations\n",
      "-----\n",
      "Episode 99 finished after 301 timesteps\n",
      "Dataset contains 30000 observations\n",
      "-----\n",
      "Episode 100 finished after 301 timesteps\n",
      "Dataset contains 30300 observations\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 101 finished after 301 timesteps\n",
      "Dataset contains 30600 observations\n",
      "-----\n",
      "Episode 102 finished after 301 timesteps\n",
      "Dataset contains 30900 observations\n",
      "-----\n",
      "Episode 103 finished after 301 timesteps\n",
      "Dataset contains 31200 observations\n",
      "-----\n",
      "Episode 104 finished after 301 timesteps\n",
      "Dataset contains 31500 observations\n",
      "-----\n",
      "Episode 105 finished after 301 timesteps\n",
      "Dataset contains 31800 observations\n",
      "-----\n",
      "Episode 106 finished after 301 timesteps\n",
      "Dataset contains 32100 observations\n",
      "-----\n",
      "Episode 107 finished after 301 timesteps\n",
      "Dataset contains 32400 observations\n",
      "-----\n",
      "Episode 108 finished after 301 timesteps\n",
      "Dataset contains 32700 observations\n",
      "-----\n",
      "Episode 109 finished after 301 timesteps\n",
      "Dataset contains 33000 observations\n",
      "-----\n",
      "Episode 110 finished after 301 timesteps\n",
      "Dataset contains 33300 observations\n",
      "-----\n",
      "Episode 111 finished after 301 timesteps\n",
      "Dataset contains 33600 observations\n",
      "-----\n",
      "Episode 112 finished after 301 timesteps\n",
      "Dataset contains 33900 observations\n",
      "-----\n",
      "Episode 113 finished after 301 timesteps\n",
      "Dataset contains 34200 observations\n",
      "-----\n",
      "Episode 114 finished after 301 timesteps\n",
      "Dataset contains 34500 observations\n",
      "-----\n",
      "Episode 115 finished after 301 timesteps\n",
      "Dataset contains 34800 observations\n",
      "-----\n",
      "Episode 116 finished after 301 timesteps\n",
      "Dataset contains 35100 observations\n",
      "-----\n",
      "Episode 117 finished after 301 timesteps\n",
      "Dataset contains 35400 observations\n",
      "-----\n",
      "Episode 118 finished after 301 timesteps\n",
      "Dataset contains 35700 observations\n",
      "-----\n",
      "Episode 119 finished after 301 timesteps\n",
      "Dataset contains 36000 observations\n",
      "-----\n",
      "Episode 120 finished after 301 timesteps\n",
      "Dataset contains 36300 observations\n",
      "-----\n",
      "Episode 121 finished after 301 timesteps\n",
      "Dataset contains 36600 observations\n",
      "-----\n",
      "Episode 122 finished after 301 timesteps\n",
      "Dataset contains 36900 observations\n",
      "-----\n",
      "Episode 123 finished after 301 timesteps\n",
      "Dataset contains 37200 observations\n",
      "-----\n",
      "Episode 124 finished after 301 timesteps\n",
      "Dataset contains 37500 observations\n",
      "-----\n",
      "Episode 125 finished after 301 timesteps\n",
      "Dataset contains 37800 observations\n",
      "-----\n",
      "Episode 126 finished after 301 timesteps\n",
      "Dataset contains 38100 observations\n",
      "-----\n",
      "Episode 127 finished after 301 timesteps\n",
      "Dataset contains 38400 observations\n",
      "-----\n",
      "Episode 128 finished after 301 timesteps\n",
      "Dataset contains 38700 observations\n",
      "-----\n",
      "Episode 129 finished after 301 timesteps\n",
      "Dataset contains 39000 observations\n",
      "-----\n",
      "Episode 130 finished after 301 timesteps\n",
      "Dataset contains 39300 observations\n",
      "-----\n",
      "Episode 131 finished after 301 timesteps\n",
      "Dataset contains 39600 observations\n",
      "-----\n",
      "Episode 132 finished after 301 timesteps\n",
      "Dataset contains 39900 observations\n",
      "-----\n",
      "Episode 133 finished after 301 timesteps\n",
      "Dataset contains 40200 observations\n",
      "-----\n",
      "Episode 134 finished after 301 timesteps\n",
      "Dataset contains 40500 observations\n",
      "-----\n",
      "Episode 135 finished after 301 timesteps\n",
      "Dataset contains 40800 observations\n",
      "-----\n",
      "Episode 136 finished after 301 timesteps\n",
      "Dataset contains 41100 observations\n",
      "-----\n",
      "Episode 137 finished after 301 timesteps\n",
      "Dataset contains 41400 observations\n",
      "-----\n",
      "Episode 138 finished after 301 timesteps\n",
      "Dataset contains 41700 observations\n",
      "-----\n",
      "Episode 139 finished after 301 timesteps\n",
      "Dataset contains 42000 observations\n",
      "-----\n",
      "Episode 140 finished after 301 timesteps\n",
      "Dataset contains 42300 observations\n",
      "-----\n",
      "Episode 141 finished after 301 timesteps\n",
      "Dataset contains 42600 observations\n",
      "-----\n",
      "Episode 142 finished after 301 timesteps\n",
      "Dataset contains 42900 observations\n",
      "-----\n",
      "Episode 143 finished after 301 timesteps\n",
      "Dataset contains 43200 observations\n",
      "-----\n",
      "Episode 144 finished after 301 timesteps\n",
      "Dataset contains 43500 observations\n",
      "-----\n",
      "Episode 145 finished after 301 timesteps\n",
      "Dataset contains 43800 observations\n",
      "-----\n",
      "Episode 146 finished after 301 timesteps\n",
      "Dataset contains 44100 observations\n",
      "-----\n",
      "Episode 147 finished after 301 timesteps\n",
      "Dataset contains 44400 observations\n",
      "-----\n",
      "Episode 148 finished after 301 timesteps\n",
      "Dataset contains 44700 observations\n",
      "-----\n",
      "Episode 149 finished after 301 timesteps\n",
      "Dataset contains 45000 observations\n",
      "-----\n",
      "Episode 150 finished after 301 timesteps\n",
      "Dataset contains 45300 observations\n",
      "-----\n",
      "Episode 151 finished after 301 timesteps\n",
      "Dataset contains 45600 observations\n",
      "-----\n",
      "Episode 152 finished after 301 timesteps\n",
      "Dataset contains 45900 observations\n",
      "-----\n",
      "Episode 153 finished after 301 timesteps\n",
      "Dataset contains 46200 observations\n",
      "-----\n",
      "Episode 154 finished after 301 timesteps\n",
      "Dataset contains 46500 observations\n",
      "-----\n",
      "Episode 155 finished after 301 timesteps\n",
      "Dataset contains 46800 observations\n",
      "-----\n",
      "Episode 156 finished after 301 timesteps\n",
      "Dataset contains 47100 observations\n",
      "-----\n",
      "Episode 157 finished after 301 timesteps\n",
      "Dataset contains 47400 observations\n",
      "-----\n",
      "Episode 158 finished after 301 timesteps\n",
      "Dataset contains 47700 observations\n",
      "-----\n",
      "Episode 159 finished after 301 timesteps\n",
      "Dataset contains 48000 observations\n",
      "-----\n",
      "Episode 160 finished after 301 timesteps\n",
      "Dataset contains 48300 observations\n",
      "-----\n",
      "Episode 161 finished after 301 timesteps\n",
      "Dataset contains 48600 observations\n",
      "-----\n",
      "Episode 162 finished after 301 timesteps\n",
      "Dataset contains 48900 observations\n",
      "-----\n",
      "Episode 163 finished after 301 timesteps\n",
      "Dataset contains 49200 observations\n",
      "-----\n",
      "Episode 164 finished after 301 timesteps\n",
      "Dataset contains 49500 observations\n",
      "-----\n",
      "Episode 165 finished after 301 timesteps\n",
      "Dataset contains 49800 observations\n",
      "-----\n",
      "Episode 166 finished after 301 timesteps\n",
      "Dataset contains 50100 observations\n",
      "-----\n",
      "Episode 167 finished after 301 timesteps\n",
      "Dataset contains 50400 observations\n",
      "-----\n",
      "Episode 168 finished after 301 timesteps\n",
      "Dataset contains 50700 observations\n",
      "-----\n",
      "Episode 169 finished after 301 timesteps\n",
      "Dataset contains 51000 observations\n",
      "-----\n",
      "Episode 170 finished after 301 timesteps\n",
      "Dataset contains 51300 observations\n",
      "-----\n",
      "Episode 171 finished after 301 timesteps\n",
      "Dataset contains 51600 observations\n",
      "-----\n",
      "Episode 172 finished after 301 timesteps\n",
      "Dataset contains 51900 observations\n",
      "-----\n",
      "Episode 173 finished after 301 timesteps\n",
      "Dataset contains 52200 observations\n",
      "-----\n",
      "Episode 174 finished after 301 timesteps\n",
      "Dataset contains 52500 observations\n",
      "-----\n",
      "Episode 175 finished after 301 timesteps\n",
      "Dataset contains 52800 observations\n",
      "-----\n",
      "Episode 176 finished after 301 timesteps\n",
      "Dataset contains 53100 observations\n",
      "-----\n",
      "Episode 177 finished after 301 timesteps\n",
      "Dataset contains 53400 observations\n",
      "-----\n",
      "Episode 178 finished after 301 timesteps\n",
      "Dataset contains 53700 observations\n",
      "-----\n",
      "Episode 179 finished after 301 timesteps\n",
      "Dataset contains 54000 observations\n",
      "-----\n",
      "Episode 180 finished after 301 timesteps\n",
      "Dataset contains 54300 observations\n",
      "-----\n",
      "Episode 181 finished after 301 timesteps\n",
      "Dataset contains 54600 observations\n",
      "-----\n",
      "Episode 182 finished after 301 timesteps\n",
      "Dataset contains 54900 observations\n",
      "-----\n",
      "Episode 183 finished after 301 timesteps\n",
      "Dataset contains 55200 observations\n",
      "-----\n",
      "Episode 184 finished after 301 timesteps\n",
      "Dataset contains 55500 observations\n",
      "-----\n",
      "Episode 185 finished after 301 timesteps\n",
      "Dataset contains 55800 observations\n",
      "-----\n",
      "Episode 186 finished after 301 timesteps\n",
      "Dataset contains 56100 observations\n",
      "-----\n",
      "Episode 187 finished after 301 timesteps\n",
      "Dataset contains 56400 observations\n",
      "-----\n",
      "Episode 188 finished after 301 timesteps\n",
      "Dataset contains 56700 observations\n",
      "-----\n",
      "Episode 189 finished after 301 timesteps\n",
      "Dataset contains 57000 observations\n",
      "-----\n",
      "Episode 190 finished after 301 timesteps\n",
      "Dataset contains 57300 observations\n",
      "-----\n",
      "Episode 191 finished after 301 timesteps\n",
      "Dataset contains 57600 observations\n",
      "-----\n",
      "Episode 192 finished after 301 timesteps\n",
      "Dataset contains 57900 observations\n",
      "-----\n",
      "Episode 193 finished after 301 timesteps\n",
      "Dataset contains 58200 observations\n",
      "-----\n",
      "Episode 194 finished after 301 timesteps\n",
      "Dataset contains 58500 observations\n",
      "-----\n",
      "Episode 195 finished after 301 timesteps\n",
      "Dataset contains 58800 observations\n",
      "-----\n",
      "Episode 196 finished after 301 timesteps\n",
      "Dataset contains 59100 observations\n",
      "-----\n",
      "Episode 197 finished after 301 timesteps\n",
      "Dataset contains 59400 observations\n",
      "-----\n",
      "Episode 198 finished after 301 timesteps\n",
      "Dataset contains 59700 observations\n",
      "-----\n",
      "Episode 199 finished after 301 timesteps\n",
      "Dataset contains 60000 observations\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200 finished after 301 timesteps\n",
      "Dataset contains 60300 observations\n",
      "-----\n",
      "Episode 201 finished after 301 timesteps\n",
      "Dataset contains 60600 observations\n",
      "-----\n",
      "Episode 202 finished after 301 timesteps\n",
      "Dataset contains 60900 observations\n",
      "-----\n",
      "Episode 203 finished after 301 timesteps\n",
      "Dataset contains 61200 observations\n",
      "-----\n",
      "Episode 204 finished after 301 timesteps\n",
      "Dataset contains 61500 observations\n",
      "-----\n",
      "Episode 205 finished after 301 timesteps\n",
      "Dataset contains 61800 observations\n",
      "-----\n",
      "Episode 206 finished after 301 timesteps\n",
      "Dataset contains 62100 observations\n",
      "-----\n",
      "Episode 207 finished after 301 timesteps\n",
      "Dataset contains 62400 observations\n",
      "-----\n",
      "Episode 208 finished after 301 timesteps\n",
      "Dataset contains 62700 observations\n",
      "-----\n",
      "Episode 209 finished after 301 timesteps\n",
      "Dataset contains 63000 observations\n",
      "-----\n",
      "Episode 210 finished after 301 timesteps\n",
      "Dataset contains 63300 observations\n",
      "-----\n",
      "Episode 211 finished after 301 timesteps\n",
      "Dataset contains 63600 observations\n",
      "-----\n",
      "Episode 212 finished after 301 timesteps\n",
      "Dataset contains 63900 observations\n",
      "-----\n",
      "Episode 213 finished after 301 timesteps\n",
      "Dataset contains 64200 observations\n",
      "-----\n",
      "Episode 214 finished after 301 timesteps\n",
      "Dataset contains 64500 observations\n",
      "-----\n",
      "Episode 215 finished after 301 timesteps\n",
      "Dataset contains 64800 observations\n",
      "-----\n",
      "Episode 216 finished after 301 timesteps\n",
      "Dataset contains 65100 observations\n",
      "-----\n",
      "Episode 217 finished after 301 timesteps\n",
      "Dataset contains 65400 observations\n",
      "-----\n",
      "Episode 218 finished after 301 timesteps\n",
      "Dataset contains 65700 observations\n",
      "-----\n",
      "Episode 219 finished after 301 timesteps\n",
      "Dataset contains 66000 observations\n",
      "-----\n",
      "Episode 220 finished after 301 timesteps\n",
      "Dataset contains 66300 observations\n",
      "-----\n",
      "Episode 221 finished after 301 timesteps\n",
      "Dataset contains 66600 observations\n",
      "-----\n",
      "Episode 222 finished after 301 timesteps\n",
      "Dataset contains 66900 observations\n",
      "-----\n",
      "Episode 223 finished after 301 timesteps\n",
      "Dataset contains 67200 observations\n",
      "-----\n",
      "Episode 224 finished after 301 timesteps\n",
      "Dataset contains 67500 observations\n",
      "-----\n",
      "Episode 225 finished after 301 timesteps\n",
      "Dataset contains 67800 observations\n",
      "-----\n",
      "Episode 226 finished after 301 timesteps\n",
      "Dataset contains 68100 observations\n",
      "-----\n",
      "Episode 227 finished after 301 timesteps\n",
      "Dataset contains 68400 observations\n",
      "-----\n",
      "Episode 228 finished after 301 timesteps\n",
      "Dataset contains 68700 observations\n",
      "-----\n",
      "Episode 229 finished after 301 timesteps\n",
      "Dataset contains 69000 observations\n",
      "-----\n",
      "Episode 230 finished after 301 timesteps\n",
      "Dataset contains 69300 observations\n",
      "-----\n",
      "Episode 231 finished after 301 timesteps\n",
      "Dataset contains 69600 observations\n",
      "-----\n",
      "Episode 232 finished after 301 timesteps\n",
      "Dataset contains 69900 observations\n",
      "-----\n",
      "Episode 233 finished after 301 timesteps\n",
      "Dataset contains 70200 observations\n",
      "-----\n",
      "Episode 234 finished after 301 timesteps\n",
      "Dataset contains 70500 observations\n",
      "-----\n",
      "Episode 235 finished after 301 timesteps\n",
      "Dataset contains 70800 observations\n",
      "-----\n",
      "Episode 236 finished after 301 timesteps\n",
      "Dataset contains 71100 observations\n",
      "-----\n",
      "Episode 237 finished after 301 timesteps\n",
      "Dataset contains 71400 observations\n",
      "-----\n",
      "Episode 238 finished after 301 timesteps\n",
      "Dataset contains 71700 observations\n",
      "-----\n",
      "Episode 239 finished after 301 timesteps\n",
      "Dataset contains 72000 observations\n",
      "-----\n",
      "Episode 240 finished after 301 timesteps\n",
      "Dataset contains 72300 observations\n",
      "-----\n",
      "Episode 241 finished after 301 timesteps\n",
      "Dataset contains 72600 observations\n",
      "-----\n",
      "Episode 242 finished after 301 timesteps\n",
      "Dataset contains 72900 observations\n",
      "-----\n",
      "Episode 243 finished after 301 timesteps\n",
      "Dataset contains 73200 observations\n",
      "-----\n",
      "Episode 244 finished after 301 timesteps\n",
      "Dataset contains 73500 observations\n",
      "-----\n",
      "Episode 245 finished after 301 timesteps\n",
      "Dataset contains 73800 observations\n",
      "-----\n",
      "Episode 246 finished after 301 timesteps\n",
      "Dataset contains 74100 observations\n",
      "-----\n",
      "Episode 247 finished after 301 timesteps\n",
      "Dataset contains 74400 observations\n",
      "-----\n",
      "Episode 248 finished after 301 timesteps\n",
      "Dataset contains 74700 observations\n",
      "-----\n",
      "Episode 249 finished after 301 timesteps\n",
      "Dataset contains 75000 observations\n",
      "-----\n",
      "Episode 250 finished after 301 timesteps\n",
      "Dataset contains 75300 observations\n",
      "-----\n",
      "Episode 251 finished after 301 timesteps\n",
      "Dataset contains 75600 observations\n",
      "-----\n",
      "Episode 252 finished after 301 timesteps\n",
      "Dataset contains 75900 observations\n",
      "-----\n",
      "Episode 253 finished after 301 timesteps\n",
      "Dataset contains 76200 observations\n",
      "-----\n",
      "Episode 254 finished after 301 timesteps\n",
      "Dataset contains 76500 observations\n",
      "-----\n",
      "Episode 255 finished after 301 timesteps\n",
      "Dataset contains 76800 observations\n",
      "-----\n",
      "Episode 256 finished after 301 timesteps\n",
      "Dataset contains 77100 observations\n",
      "-----\n",
      "Episode 257 finished after 301 timesteps\n",
      "Dataset contains 77400 observations\n",
      "-----\n",
      "Episode 258 finished after 301 timesteps\n",
      "Dataset contains 77700 observations\n",
      "-----\n",
      "Episode 259 finished after 301 timesteps\n",
      "Dataset contains 78000 observations\n",
      "-----\n",
      "Episode 260 finished after 301 timesteps\n",
      "Dataset contains 78300 observations\n",
      "-----\n",
      "Episode 261 finished after 301 timesteps\n",
      "Dataset contains 78600 observations\n",
      "-----\n",
      "Episode 262 finished after 301 timesteps\n",
      "Dataset contains 78900 observations\n",
      "-----\n",
      "Episode 263 finished after 301 timesteps\n",
      "Dataset contains 79200 observations\n",
      "-----\n",
      "Episode 264 finished after 301 timesteps\n",
      "Dataset contains 79500 observations\n",
      "-----\n",
      "Episode 265 finished after 301 timesteps\n",
      "Dataset contains 79800 observations\n",
      "-----\n",
      "Episode 266 finished after 301 timesteps\n",
      "Dataset contains 80100 observations\n",
      "-----\n",
      "Episode 267 finished after 301 timesteps\n",
      "Dataset contains 80400 observations\n",
      "-----\n",
      "Episode 268 finished after 301 timesteps\n",
      "Dataset contains 80700 observations\n",
      "-----\n",
      "Episode 269 finished after 301 timesteps\n",
      "Dataset contains 81000 observations\n",
      "-----\n",
      "Episode 270 finished after 301 timesteps\n",
      "Dataset contains 81300 observations\n",
      "-----\n",
      "Episode 271 finished after 301 timesteps\n",
      "Dataset contains 81600 observations\n",
      "-----\n",
      "Episode 272 finished after 301 timesteps\n",
      "Dataset contains 81900 observations\n",
      "-----\n",
      "Episode 273 finished after 301 timesteps\n",
      "Dataset contains 82200 observations\n",
      "-----\n",
      "Episode 274 finished after 301 timesteps\n",
      "Dataset contains 82500 observations\n",
      "-----\n",
      "Episode 275 finished after 301 timesteps\n",
      "Dataset contains 82800 observations\n",
      "-----\n",
      "Episode 276 finished after 301 timesteps\n",
      "Dataset contains 83100 observations\n",
      "-----\n",
      "Episode 277 finished after 301 timesteps\n",
      "Dataset contains 83400 observations\n",
      "-----\n",
      "Episode 278 finished after 301 timesteps\n",
      "Dataset contains 83700 observations\n",
      "-----\n",
      "Episode 279 finished after 301 timesteps\n",
      "Dataset contains 84000 observations\n",
      "-----\n",
      "Episode 280 finished after 301 timesteps\n",
      "Dataset contains 84300 observations\n",
      "-----\n",
      "Episode 281 finished after 301 timesteps\n",
      "Dataset contains 84600 observations\n",
      "-----\n",
      "Episode 282 finished after 301 timesteps\n",
      "Dataset contains 84900 observations\n",
      "-----\n",
      "Episode 283 finished after 301 timesteps\n",
      "Dataset contains 85200 observations\n",
      "-----\n",
      "Episode 284 finished after 301 timesteps\n",
      "Dataset contains 85500 observations\n",
      "-----\n",
      "Episode 285 finished after 301 timesteps\n",
      "Dataset contains 85800 observations\n",
      "-----\n",
      "Episode 286 finished after 301 timesteps\n",
      "Dataset contains 86100 observations\n",
      "-----\n",
      "Episode 287 finished after 301 timesteps\n",
      "Dataset contains 86400 observations\n",
      "-----\n",
      "Episode 288 finished after 301 timesteps\n",
      "Dataset contains 86700 observations\n",
      "-----\n",
      "Episode 289 finished after 301 timesteps\n",
      "Dataset contains 87000 observations\n",
      "-----\n",
      "Episode 290 finished after 301 timesteps\n",
      "Dataset contains 87300 observations\n",
      "-----\n",
      "Episode 291 finished after 301 timesteps\n",
      "Dataset contains 87600 observations\n",
      "-----\n",
      "Episode 292 finished after 301 timesteps\n",
      "Dataset contains 87900 observations\n",
      "-----\n",
      "Episode 293 finished after 301 timesteps\n",
      "Dataset contains 88200 observations\n",
      "-----\n",
      "Episode 294 finished after 301 timesteps\n",
      "Dataset contains 88500 observations\n",
      "-----\n",
      "Episode 295 finished after 301 timesteps\n",
      "Dataset contains 88800 observations\n",
      "-----\n",
      "Episode 296 finished after 301 timesteps\n",
      "Dataset contains 89100 observations\n",
      "-----\n",
      "Episode 297 finished after 301 timesteps\n",
      "Dataset contains 89400 observations\n",
      "-----\n",
      "Episode 298 finished after 301 timesteps\n",
      "Dataset contains 89700 observations\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 299 finished after 301 timesteps\n",
      "Dataset contains 90000 observations\n",
      "-----\n",
      "Episode 300 finished after 301 timesteps\n",
      "Dataset contains 90300 observations\n",
      "-----\n",
      "Episode 301 finished after 301 timesteps\n",
      "Dataset contains 90600 observations\n",
      "-----\n",
      "Episode 302 finished after 301 timesteps\n",
      "Dataset contains 90900 observations\n",
      "-----\n",
      "Episode 303 finished after 301 timesteps\n",
      "Dataset contains 91200 observations\n",
      "-----\n",
      "Episode 304 finished after 301 timesteps\n",
      "Dataset contains 91500 observations\n",
      "-----\n",
      "Episode 305 finished after 301 timesteps\n",
      "Dataset contains 91800 observations\n",
      "-----\n",
      "Episode 306 finished after 301 timesteps\n",
      "Dataset contains 92100 observations\n",
      "-----\n",
      "Episode 307 finished after 301 timesteps\n",
      "Dataset contains 92400 observations\n",
      "-----\n",
      "Episode 308 finished after 301 timesteps\n",
      "Dataset contains 92700 observations\n",
      "-----\n",
      "Episode 309 finished after 301 timesteps\n",
      "Dataset contains 93000 observations\n",
      "-----\n",
      "Episode 310 finished after 301 timesteps\n",
      "Dataset contains 93300 observations\n",
      "-----\n",
      "Episode 311 finished after 301 timesteps\n",
      "Dataset contains 93600 observations\n",
      "-----\n",
      "Episode 312 finished after 301 timesteps\n",
      "Dataset contains 93900 observations\n",
      "-----\n",
      "Episode 313 finished after 301 timesteps\n",
      "Dataset contains 94200 observations\n",
      "-----\n",
      "Episode 314 finished after 301 timesteps\n",
      "Dataset contains 94500 observations\n",
      "-----\n",
      "Episode 315 finished after 301 timesteps\n",
      "Dataset contains 94800 observations\n",
      "-----\n",
      "Episode 316 finished after 301 timesteps\n",
      "Dataset contains 95100 observations\n",
      "-----\n",
      "Episode 317 finished after 301 timesteps\n",
      "Dataset contains 95400 observations\n",
      "-----\n",
      "Episode 318 finished after 301 timesteps\n",
      "Dataset contains 95700 observations\n",
      "-----\n",
      "Episode 319 finished after 301 timesteps\n",
      "Dataset contains 96000 observations\n",
      "-----\n",
      "Episode 320 finished after 301 timesteps\n",
      "Dataset contains 96300 observations\n",
      "-----\n",
      "Episode 321 finished after 301 timesteps\n",
      "Dataset contains 96600 observations\n",
      "-----\n",
      "Episode 322 finished after 301 timesteps\n",
      "Dataset contains 96900 observations\n",
      "-----\n",
      "Episode 323 finished after 301 timesteps\n",
      "Dataset contains 97200 observations\n",
      "-----\n",
      "Episode 324 finished after 301 timesteps\n",
      "Dataset contains 97500 observations\n",
      "-----\n",
      "Episode 325 finished after 301 timesteps\n",
      "Dataset contains 97800 observations\n",
      "-----\n",
      "Episode 326 finished after 301 timesteps\n",
      "Dataset contains 98100 observations\n",
      "-----\n",
      "Episode 327 finished after 301 timesteps\n",
      "Dataset contains 98400 observations\n",
      "-----\n",
      "Episode 328 finished after 301 timesteps\n",
      "Dataset contains 98700 observations\n",
      "-----\n",
      "Episode 329 finished after 301 timesteps\n",
      "Dataset contains 99000 observations\n",
      "-----\n",
      "Episode 330 finished after 301 timesteps\n",
      "Dataset contains 99300 observations\n",
      "-----\n",
      "Episode 331 finished after 301 timesteps\n",
      "Dataset contains 99600 observations\n",
      "-----\n",
      "Episode 332 finished after 301 timesteps\n",
      "Dataset contains 99900 observations\n",
      "-----\n",
      "Episode 333 finished after 301 timesteps\n",
      "Dataset contains 100200 observations\n",
      "-----\n",
      "Episode 334 finished after 301 timesteps\n",
      "Dataset contains 100500 observations\n",
      "-----\n",
      "Episode 335 finished after 301 timesteps\n",
      "Dataset contains 100800 observations\n",
      "-----\n",
      "Episode 336 finished after 301 timesteps\n",
      "Dataset contains 101100 observations\n",
      "-----\n",
      "Episode 337 finished after 301 timesteps\n",
      "Dataset contains 101400 observations\n",
      "-----\n",
      "Episode 338 finished after 301 timesteps\n",
      "Dataset contains 101700 observations\n",
      "-----\n",
      "Episode 339 finished after 301 timesteps\n",
      "Dataset contains 102000 observations\n",
      "-----\n",
      "Episode 340 finished after 301 timesteps\n",
      "Dataset contains 102300 observations\n",
      "-----\n",
      "Episode 341 finished after 301 timesteps\n",
      "Dataset contains 102600 observations\n",
      "-----\n",
      "Episode 342 finished after 301 timesteps\n",
      "Dataset contains 102900 observations\n",
      "-----\n",
      "Episode 343 finished after 301 timesteps\n",
      "Dataset contains 103200 observations\n",
      "-----\n",
      "Episode 344 finished after 301 timesteps\n",
      "Dataset contains 103500 observations\n",
      "-----\n",
      "Episode 345 finished after 301 timesteps\n",
      "Dataset contains 103800 observations\n",
      "-----\n",
      "Episode 346 finished after 301 timesteps\n",
      "Dataset contains 104100 observations\n",
      "-----\n",
      "Episode 347 finished after 301 timesteps\n",
      "Dataset contains 104400 observations\n",
      "-----\n",
      "Episode 348 finished after 301 timesteps\n",
      "Dataset contains 104700 observations\n",
      "-----\n",
      "Episode 349 finished after 301 timesteps\n",
      "Dataset contains 105000 observations\n",
      "-----\n",
      "Episode 350 finished after 301 timesteps\n",
      "Dataset contains 105300 observations\n",
      "-----\n",
      "Episode 351 finished after 301 timesteps\n",
      "Dataset contains 105600 observations\n",
      "-----\n",
      "Episode 352 finished after 301 timesteps\n",
      "Dataset contains 105900 observations\n",
      "-----\n",
      "Episode 353 finished after 301 timesteps\n",
      "Dataset contains 106200 observations\n",
      "-----\n",
      "Episode 354 finished after 301 timesteps\n",
      "Dataset contains 106500 observations\n",
      "-----\n",
      "Episode 355 finished after 301 timesteps\n",
      "Dataset contains 106800 observations\n",
      "-----\n",
      "Episode 356 finished after 301 timesteps\n",
      "Dataset contains 107100 observations\n",
      "-----\n",
      "Episode 357 finished after 301 timesteps\n",
      "Dataset contains 107400 observations\n",
      "-----\n",
      "Episode 358 finished after 301 timesteps\n",
      "Dataset contains 107700 observations\n",
      "-----\n",
      "Episode 359 finished after 301 timesteps\n",
      "Dataset contains 108000 observations\n",
      "-----\n",
      "Episode 360 finished after 301 timesteps\n",
      "Dataset contains 108300 observations\n",
      "-----\n",
      "Episode 361 finished after 301 timesteps\n",
      "Dataset contains 108600 observations\n",
      "-----\n",
      "Episode 362 finished after 301 timesteps\n",
      "Dataset contains 108900 observations\n",
      "-----\n",
      "Episode 363 finished after 301 timesteps\n",
      "Dataset contains 109200 observations\n",
      "-----\n",
      "Episode 364 finished after 301 timesteps\n",
      "Dataset contains 109500 observations\n",
      "-----\n",
      "Episode 365 finished after 301 timesteps\n",
      "Dataset contains 109800 observations\n",
      "-----\n",
      "Episode 366 finished after 301 timesteps\n",
      "Dataset contains 110100 observations\n",
      "-----\n",
      "Episode 367 finished after 301 timesteps\n",
      "Dataset contains 110400 observations\n",
      "-----\n",
      "Episode 368 finished after 301 timesteps\n",
      "Dataset contains 110700 observations\n",
      "-----\n",
      "Episode 369 finished after 301 timesteps\n",
      "Dataset contains 111000 observations\n",
      "-----\n",
      "Episode 370 finished after 301 timesteps\n",
      "Dataset contains 111300 observations\n",
      "-----\n",
      "Episode 371 finished after 301 timesteps\n",
      "Dataset contains 111600 observations\n",
      "-----\n",
      "Episode 372 finished after 301 timesteps\n",
      "Dataset contains 111900 observations\n",
      "-----\n",
      "Episode 373 finished after 301 timesteps\n",
      "Dataset contains 112200 observations\n",
      "-----\n",
      "Episode 374 finished after 301 timesteps\n",
      "Dataset contains 112500 observations\n",
      "-----\n",
      "Episode 375 finished after 301 timesteps\n",
      "Dataset contains 112800 observations\n",
      "-----\n",
      "Episode 376 finished after 301 timesteps\n",
      "Dataset contains 113100 observations\n",
      "-----\n",
      "Episode 377 finished after 301 timesteps\n",
      "Dataset contains 113400 observations\n",
      "-----\n",
      "Episode 378 finished after 301 timesteps\n",
      "Dataset contains 113700 observations\n",
      "-----\n",
      "Episode 379 finished after 301 timesteps\n",
      "Dataset contains 114000 observations\n",
      "-----\n",
      "Episode 380 finished after 301 timesteps\n",
      "Dataset contains 114300 observations\n",
      "-----\n",
      "Episode 381 finished after 301 timesteps\n",
      "Dataset contains 114600 observations\n",
      "-----\n",
      "Episode 382 finished after 301 timesteps\n",
      "Dataset contains 114900 observations\n",
      "-----\n",
      "Episode 383 finished after 301 timesteps\n",
      "Dataset contains 115200 observations\n",
      "-----\n",
      "Episode 384 finished after 301 timesteps\n",
      "Dataset contains 115500 observations\n",
      "-----\n",
      "Episode 385 finished after 301 timesteps\n",
      "Dataset contains 115800 observations\n",
      "-----\n",
      "Episode 386 finished after 301 timesteps\n",
      "Dataset contains 116100 observations\n",
      "-----\n",
      "Episode 387 finished after 301 timesteps\n",
      "Dataset contains 116400 observations\n",
      "-----\n",
      "Episode 388 finished after 301 timesteps\n",
      "Dataset contains 116700 observations\n",
      "-----\n",
      "Episode 389 finished after 301 timesteps\n",
      "Dataset contains 117000 observations\n",
      "-----\n",
      "Episode 390 finished after 301 timesteps\n",
      "Dataset contains 117300 observations\n",
      "-----\n",
      "Episode 391 finished after 301 timesteps\n",
      "Dataset contains 117600 observations\n",
      "-----\n",
      "Episode 392 finished after 301 timesteps\n",
      "Dataset contains 117900 observations\n",
      "-----\n",
      "Episode 393 finished after 301 timesteps\n",
      "Dataset contains 118200 observations\n",
      "-----\n",
      "Episode 394 finished after 301 timesteps\n",
      "Dataset contains 118500 observations\n",
      "-----\n",
      "Episode 395 finished after 301 timesteps\n",
      "Dataset contains 118800 observations\n",
      "-----\n",
      "Episode 396 finished after 301 timesteps\n",
      "Dataset contains 119100 observations\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 397 finished after 301 timesteps\n",
      "Dataset contains 119400 observations\n",
      "-----\n",
      "Episode 398 finished after 301 timesteps\n",
      "Dataset contains 119700 observations\n",
      "-----\n",
      "Episode 399 finished after 301 timesteps\n",
      "Dataset contains 120000 observations\n",
      "-----\n",
      "Episode 400 finished after 301 timesteps\n",
      "Dataset contains 120300 observations\n",
      "-----\n",
      "Episode 401 finished after 301 timesteps\n",
      "Dataset contains 120600 observations\n",
      "-----\n",
      "Episode 402 finished after 301 timesteps\n",
      "Dataset contains 120900 observations\n",
      "-----\n",
      "Episode 403 finished after 301 timesteps\n",
      "Dataset contains 121200 observations\n",
      "-----\n",
      "Episode 404 finished after 301 timesteps\n",
      "Dataset contains 121500 observations\n",
      "-----\n",
      "Episode 405 finished after 301 timesteps\n",
      "Dataset contains 121800 observations\n",
      "-----\n",
      "Episode 406 finished after 301 timesteps\n",
      "Dataset contains 122100 observations\n",
      "-----\n",
      "Episode 407 finished after 301 timesteps\n",
      "Dataset contains 122400 observations\n",
      "-----\n",
      "Episode 408 finished after 301 timesteps\n",
      "Dataset contains 122700 observations\n",
      "-----\n",
      "Episode 409 finished after 301 timesteps\n",
      "Dataset contains 123000 observations\n",
      "-----\n",
      "Episode 410 finished after 301 timesteps\n",
      "Dataset contains 123300 observations\n",
      "-----\n",
      "Episode 411 finished after 301 timesteps\n",
      "Dataset contains 123600 observations\n",
      "-----\n",
      "Episode 412 finished after 301 timesteps\n",
      "Dataset contains 123900 observations\n",
      "-----\n",
      "Episode 413 finished after 301 timesteps\n",
      "Dataset contains 124200 observations\n",
      "-----\n",
      "Episode 414 finished after 301 timesteps\n",
      "Dataset contains 124500 observations\n",
      "-----\n",
      "Episode 415 finished after 301 timesteps\n",
      "Dataset contains 124800 observations\n",
      "-----\n",
      "Episode 416 finished after 301 timesteps\n",
      "Dataset contains 125100 observations\n",
      "-----\n",
      "Episode 417 finished after 301 timesteps\n",
      "Dataset contains 125400 observations\n",
      "-----\n",
      "Episode 418 finished after 301 timesteps\n",
      "Dataset contains 125700 observations\n",
      "-----\n",
      "Episode 419 finished after 301 timesteps\n",
      "Dataset contains 126000 observations\n",
      "-----\n",
      "Episode 420 finished after 301 timesteps\n",
      "Dataset contains 126300 observations\n",
      "-----\n",
      "Episode 421 finished after 301 timesteps\n",
      "Dataset contains 126600 observations\n",
      "-----\n",
      "Episode 422 finished after 301 timesteps\n",
      "Dataset contains 126900 observations\n",
      "-----\n",
      "Episode 423 finished after 301 timesteps\n",
      "Dataset contains 127200 observations\n",
      "-----\n",
      "Episode 424 finished after 301 timesteps\n",
      "Dataset contains 127500 observations\n",
      "-----\n",
      "Episode 425 finished after 301 timesteps\n",
      "Dataset contains 127800 observations\n",
      "-----\n",
      "Episode 426 finished after 301 timesteps\n",
      "Dataset contains 128100 observations\n",
      "-----\n",
      "Episode 427 finished after 301 timesteps\n",
      "Dataset contains 128400 observations\n",
      "-----\n",
      "Episode 428 finished after 301 timesteps\n",
      "Dataset contains 128700 observations\n",
      "-----\n",
      "Episode 429 finished after 301 timesteps\n",
      "Dataset contains 129000 observations\n",
      "-----\n",
      "Episode 430 finished after 301 timesteps\n",
      "Dataset contains 129300 observations\n",
      "-----\n",
      "Episode 431 finished after 301 timesteps\n",
      "Dataset contains 129600 observations\n",
      "-----\n",
      "Episode 432 finished after 301 timesteps\n",
      "Dataset contains 129900 observations\n",
      "-----\n",
      "Episode 433 finished after 301 timesteps\n",
      "Dataset contains 130200 observations\n",
      "-----\n",
      "Episode 434 finished after 301 timesteps\n",
      "Dataset contains 130500 observations\n",
      "-----\n",
      "Episode 435 finished after 301 timesteps\n",
      "Dataset contains 130800 observations\n",
      "-----\n",
      "Episode 436 finished after 301 timesteps\n",
      "Dataset contains 131100 observations\n",
      "-----\n",
      "Episode 437 finished after 301 timesteps\n",
      "Dataset contains 131400 observations\n",
      "-----\n",
      "Episode 438 finished after 301 timesteps\n",
      "Dataset contains 131700 observations\n",
      "-----\n",
      "Episode 439 finished after 301 timesteps\n",
      "Dataset contains 132000 observations\n",
      "-----\n",
      "Episode 440 finished after 301 timesteps\n",
      "Dataset contains 132300 observations\n",
      "-----\n",
      "Episode 441 finished after 301 timesteps\n",
      "Dataset contains 132600 observations\n",
      "-----\n",
      "Episode 442 finished after 301 timesteps\n",
      "Dataset contains 132900 observations\n",
      "-----\n",
      "Episode 443 finished after 301 timesteps\n",
      "Dataset contains 133200 observations\n",
      "-----\n",
      "Episode 444 finished after 301 timesteps\n",
      "Dataset contains 133500 observations\n",
      "-----\n",
      "Episode 445 finished after 301 timesteps\n",
      "Dataset contains 133800 observations\n",
      "-----\n",
      "Episode 446 finished after 301 timesteps\n",
      "Dataset contains 134100 observations\n",
      "-----\n",
      "Episode 447 finished after 301 timesteps\n",
      "Dataset contains 134400 observations\n",
      "-----\n",
      "Episode 448 finished after 301 timesteps\n",
      "Dataset contains 134700 observations\n",
      "-----\n",
      "Episode 449 finished after 301 timesteps\n",
      "Dataset contains 135000 observations\n",
      "-----\n",
      "Episode 450 finished after 301 timesteps\n",
      "Dataset contains 135300 observations\n",
      "-----\n",
      "Episode 451 finished after 301 timesteps\n",
      "Dataset contains 135600 observations\n",
      "-----\n",
      "Episode 452 finished after 301 timesteps\n",
      "Dataset contains 135900 observations\n",
      "-----\n",
      "Episode 453 finished after 301 timesteps\n",
      "Dataset contains 136200 observations\n",
      "-----\n",
      "Episode 454 finished after 301 timesteps\n",
      "Dataset contains 136500 observations\n",
      "-----\n",
      "Episode 455 finished after 301 timesteps\n",
      "Dataset contains 136800 observations\n",
      "-----\n",
      "Episode 456 finished after 301 timesteps\n",
      "Dataset contains 137100 observations\n",
      "-----\n",
      "Episode 457 finished after 301 timesteps\n",
      "Dataset contains 137400 observations\n",
      "-----\n",
      "Episode 458 finished after 301 timesteps\n",
      "Dataset contains 137700 observations\n",
      "-----\n",
      "Episode 459 finished after 301 timesteps\n",
      "Dataset contains 138000 observations\n",
      "-----\n",
      "Episode 460 finished after 301 timesteps\n",
      "Dataset contains 138300 observations\n",
      "-----\n",
      "Episode 461 finished after 301 timesteps\n",
      "Dataset contains 138600 observations\n",
      "-----\n",
      "Episode 462 finished after 301 timesteps\n",
      "Dataset contains 138900 observations\n",
      "-----\n",
      "Episode 463 finished after 301 timesteps\n",
      "Dataset contains 139200 observations\n",
      "-----\n",
      "Episode 464 finished after 301 timesteps\n",
      "Dataset contains 139500 observations\n",
      "-----\n",
      "Episode 465 finished after 301 timesteps\n",
      "Dataset contains 139800 observations\n",
      "-----\n",
      "Episode 466 finished after 301 timesteps\n",
      "Dataset contains 140100 observations\n",
      "-----\n",
      "Episode 467 finished after 301 timesteps\n",
      "Dataset contains 140400 observations\n",
      "-----\n",
      "Episode 468 finished after 301 timesteps\n",
      "Dataset contains 140700 observations\n",
      "-----\n",
      "Episode 469 finished after 301 timesteps\n",
      "Dataset contains 141000 observations\n",
      "-----\n",
      "Episode 470 finished after 301 timesteps\n",
      "Dataset contains 141300 observations\n",
      "-----\n",
      "Episode 471 finished after 301 timesteps\n",
      "Dataset contains 141600 observations\n",
      "-----\n",
      "Episode 472 finished after 301 timesteps\n",
      "Dataset contains 141900 observations\n",
      "-----\n",
      "Episode 473 finished after 301 timesteps\n",
      "Dataset contains 142200 observations\n",
      "-----\n",
      "Episode 474 finished after 301 timesteps\n",
      "Dataset contains 142500 observations\n",
      "-----\n",
      "Episode 475 finished after 301 timesteps\n",
      "Dataset contains 142800 observations\n",
      "-----\n",
      "Episode 476 finished after 301 timesteps\n",
      "Dataset contains 143100 observations\n",
      "-----\n",
      "Episode 477 finished after 301 timesteps\n",
      "Dataset contains 143400 observations\n",
      "-----\n",
      "Episode 478 finished after 301 timesteps\n",
      "Dataset contains 143700 observations\n",
      "-----\n",
      "Episode 479 finished after 301 timesteps\n",
      "Dataset contains 144000 observations\n",
      "-----\n",
      "Episode 480 finished after 301 timesteps\n",
      "Dataset contains 144300 observations\n",
      "-----\n",
      "Episode 481 finished after 301 timesteps\n",
      "Dataset contains 144600 observations\n",
      "-----\n",
      "Episode 482 finished after 301 timesteps\n",
      "Dataset contains 144900 observations\n",
      "-----\n",
      "Episode 483 finished after 301 timesteps\n",
      "Dataset contains 145200 observations\n",
      "-----\n",
      "Episode 484 finished after 301 timesteps\n",
      "Dataset contains 145500 observations\n",
      "-----\n",
      "Episode 485 finished after 301 timesteps\n",
      "Dataset contains 145800 observations\n",
      "-----\n",
      "Episode 486 finished after 301 timesteps\n",
      "Dataset contains 146100 observations\n",
      "-----\n",
      "Episode 487 finished after 301 timesteps\n",
      "Dataset contains 146400 observations\n",
      "-----\n",
      "Episode 488 finished after 301 timesteps\n",
      "Dataset contains 146700 observations\n",
      "-----\n",
      "Episode 489 finished after 301 timesteps\n",
      "Dataset contains 147000 observations\n",
      "-----\n",
      "Episode 490 finished after 301 timesteps\n",
      "Dataset contains 147300 observations\n",
      "-----\n",
      "Episode 491 finished after 301 timesteps\n",
      "Dataset contains 147600 observations\n",
      "-----\n",
      "Episode 492 finished after 301 timesteps\n",
      "Dataset contains 147900 observations\n",
      "-----\n",
      "Episode 493 finished after 301 timesteps\n",
      "Dataset contains 148200 observations\n",
      "-----\n",
      "Episode 494 finished after 301 timesteps\n",
      "Dataset contains 148500 observations\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 495 finished after 301 timesteps\n",
      "Dataset contains 148800 observations\n",
      "-----\n",
      "Episode 496 finished after 301 timesteps\n",
      "Dataset contains 149100 observations\n",
      "-----\n",
      "Episode 497 finished after 301 timesteps\n",
      "Dataset contains 149400 observations\n",
      "-----\n",
      "Episode 498 finished after 301 timesteps\n",
      "Dataset contains 149700 observations\n",
      "-----\n",
      "Episode 499 finished after 301 timesteps\n",
      "Dataset contains 150000 observations\n"
     ]
    }
   ],
   "source": [
    "action = np.array([0,1,0])\n",
    "for i_episode in range(500):\n",
    "    print('-----')\n",
    "    observation = env.reset()\n",
    "    env.render()\n",
    "    t = 0\n",
    "    done = False\n",
    "    obs_sequence = []\n",
    "    action_sequence = []\n",
    "    while t < 300:\n",
    "        t = t + 1\n",
    "        action = pick_random_action(t, action)\n",
    "        \n",
    "        observation = observation.astype('float32') / 255.\n",
    "              \n",
    "        obs_sequence.append(observation)\n",
    "        action_sequence.append(action)\n",
    "        \n",
    "        observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    obs_data.append(obs_sequence)\n",
    "    action_data.append(action_sequence)\n",
    "    \n",
    "    print(\"Episode {} finished after {} timesteps\".format(i_episode, t+1))\n",
    "    print(\"Dataset contains {} observations\".format(sum(map(len, obs_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./archive/data/obs_data', obs_data)\n",
    "np.save('./archive/data/action_data', action_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(action_data[1]))\n",
    "print(len(obs_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## VAE #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_x = Input(shape=original_dim)\n",
    "vae_c1 = Conv2D(filters = 32, kernel_size = 4, strides = 2, activation='relu')(vae_x)\n",
    "vae_c2 = Conv2D(filters = 64, kernel_size = 4, strides = 2, activation='relu')(vae_c1)\n",
    "vae_c3= Conv2D(filters = 64, kernel_size = 4, strides = 2, activation='relu')(vae_c2)\n",
    "vae_c4= Conv2D(filters = 128, kernel_size = 4, strides = 2, activation='relu')(vae_c3)\n",
    "\n",
    "# tmp = Model(x, c4)\n",
    "# tmp.summary()\n",
    "\n",
    "vae_z_in = Flatten()(vae_c4)\n",
    "\n",
    "vae_z_mean = Dense(z_dim)(vae_z_in)\n",
    "vae_z_log_var = Dense(z_dim)(vae_z_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], z_dim), mean=0.,stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "vae_z = Lambda(sampling, output_shape=(z_dim,))([vae_z_mean, vae_z_log_var])\n",
    "vae_z_input = Input(shape=(z_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we instantiate these layers separately so as to reuse them later\n",
    "vae_dense = Dense(1024)\n",
    "vae_dense_model = vae_dense(vae_z)\n",
    "\n",
    "vae_z_out = Reshape((1,1,1024))\n",
    "vae_z_out_model = vae_z_out(vae_dense_model)\n",
    "\n",
    "vae_d1 = Conv2DTranspose(filters = 64, kernel_size = 5, strides = 2, activation='relu')\n",
    "vae_d1_model = vae_d1(vae_z_out_model)\n",
    "vae_d2 = Conv2DTranspose(filters = 64, kernel_size = 5, strides = 2, activation='relu')\n",
    "vae_d2_model = vae_d2(vae_d1_model)\n",
    "vae_d3 = Conv2DTranspose(filters = 32, kernel_size = 6, strides = 2, activation='relu')\n",
    "vae_d3_model = vae_d3(vae_d2_model)\n",
    "vae_d4 = Conv2DTranspose(filters = 3, kernel_size = 6, strides = 2, activation='sigmoid')\n",
    "vae_d4_model = vae_d4(vae_d3_model)\n",
    "\n",
    "#### ENCODER ONLY\n",
    "\n",
    "vae_encoder = Model(vae_x, vae_z)\n",
    "\n",
    "#### DECODER ONLY\n",
    "\n",
    "vae_dense_decoder = vae_dense(vae_z_input)\n",
    "vae_z_out_decoder = vae_z_out(vae_dense_decoder)\n",
    "\n",
    "vae_d1_decoder = vae_d1(vae_z_out_decoder)\n",
    "vae_d2_decoder = vae_d2(vae_d1_decoder)\n",
    "vae_d3_decoder = vae_d3(vae_d2_decoder)\n",
    "vae_d4_decoder = vae_d4(vae_d3_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "vae = Model(vae_x, vae_d4_model)\n",
    "vae_decoder = Model(vae_z_input, vae_d4_decoder)\n",
    "#\n",
    "\n",
    "def vae_r_loss(y_true, y_pred):\n",
    "\n",
    "    return K.sum(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "\n",
    "def vae_kl_loss(y_true, y_pred):\n",
    "    return - 0.5 * K.sum(1 + vae_z_log_var - K.square(vae_z_mean) - K.exp(vae_z_log_var), axis = -1)\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    return vae_r_loss(y_true, y_pred) + vae_kl_loss(y_true, y_pred)\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss = vae_loss,  metrics = [vae_r_loss, vae_kl_loss])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 32)   1568        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 64)   32832       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 6, 64)     65600       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 2, 2, 128)    131200      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           16416       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           16416       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         33792       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 1024)   0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 5, 5, 64)     1638464     reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 13, 13, 64)   102464      conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 30, 30, 32)   73760       conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 3)    3459        conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 2,115,971\n",
      "Trainable params: 2,115,971\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              33792     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 5, 5, 64)          1638464   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 30, 30, 32)        73760     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 64, 64, 3)         3459      \n",
      "=================================================================\n",
      "Total params: 1,851,939\n",
      "Trainable params: 1,851,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 64, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array([item for obs in obs_data for item in obs])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 949s 8ms/step - loss: 69.9420 - val_loss: 44.2432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x115b84f98>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=vae_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights('./archive/models/vae_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights('./vae/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-ce56d82a6d9a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-ce56d82a6d9a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    vae_encoder.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_decoded = vae_encoder.predict(np.array([x_train[1000]]))\n",
    "x_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for idx in range(12900,len(x_train)):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(1, figsize=(20,10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x_train[idx])\n",
    "    \n",
    "    x_decoded = vae.predict(np.array([x_train[idx]]))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(x_decoded[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-983f7a434ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrnn_z_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mconc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_z_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrnn_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1835\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_input = []\n",
    "rnn_output = []\n",
    "\n",
    "for i, j in zip(obs_data, action_data):    \n",
    "    rnn_z_input = vae_encoder.predict(np.array(i))\n",
    "    conc = [np.concatenate([x,y]) for x, y in zip(rnn_z_input, j)]\n",
    "    rnn_input.append(conc[:-1])\n",
    "    rnn_output.append(np.array(rnn_z_input[1:]))\n",
    "\n",
    "rnn_input = np.array(rnn_input)\n",
    "rnn_output = np.array(rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, 35)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, None, 256), (None 299008    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 480)         123360    \n",
      "=================================================================\n",
      "Total params: 422,368\n",
      "Trainable params: 422,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, 35)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  299008      input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 299,008\n",
      "Trainable params: 299,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### THE MODEL THAT WILL BE TRAINED\n",
    "rnn_x = Input(shape=(None, z_dim + action_dim))\n",
    "lstm = LSTM(lstm_hidden_units, return_sequences=True, return_state = True)\n",
    "lstm_output, _ , _ = lstm(rnn_x)\n",
    "mdn = Dense(gaussian_mixtures * (3*z_dim) + discrete_dim)(lstm_output)\n",
    "\n",
    "rnn = Model(rnn_x, mdn)\n",
    "rnn.summary()\n",
    "\n",
    "#### THE MODEL USED DURING PREDICTION\n",
    "\n",
    "state_input_h = Input(shape=(lstm_hidden_units,))\n",
    "state_input_c = Input(shape=(lstm_hidden_units,))\n",
    "\n",
    "_ , state_h, state_c = lstm(rnn_x, initial_state = [state_input_h, state_input_c])\n",
    "\n",
    "rnn_inference = Model([rnn_x] + [state_input_h, state_input_c], [state_h, state_c])\n",
    "rnn_inference.summary()\n",
    "#rnn.initial_state()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAUSSIAN_MIXTURES = gaussian_mixtures\n",
    "Z_DIM = z_dim\n",
    "\n",
    "def get_mixture_coef(y_pred):\n",
    "    \n",
    "    d = GAUSSIAN_MIXTURES * Z_DIM\n",
    "    \n",
    "    rollout_length = K.shape(y_pred)[1]\n",
    "    \n",
    "    pi = y_pred[:,:,:d]\n",
    "    mu = y_pred[:,:,d:(2*d)]\n",
    "    log_sigma = y_pred[:,:,(2*d):(3*d)]\n",
    "    #discrete = y_pred[:,3*GAUSSIAN_MIXTURES:]\n",
    "    \n",
    "    pi = K.reshape(pi, [-1, rollout_length, GAUSSIAN_MIXTURES, Z_DIM])\n",
    "    mu = K.reshape(mu, [-1, rollout_length, GAUSSIAN_MIXTURES, Z_DIM])\n",
    "    log_sigma = K.reshape(log_sigma, [-1, rollout_length, GAUSSIAN_MIXTURES, Z_DIM])\n",
    "\n",
    "    pi = K.exp(pi) / K.sum(K.exp(pi), axis=2, keepdims=True)\n",
    "    sigma = K.exp(log_sigma)\n",
    "    \n",
    "    return pi, mu, sigma#, discrete\n",
    "\n",
    "\n",
    "def tf_normal(y_true, mu, sigma, pi):\n",
    "    rollout_length = K.shape(y_true)[1]\n",
    "    y_true = K.tile(y_true,(1,1,GAUSSIAN_MIXTURES))\n",
    "    y_true = K.reshape(y_true, [-1, rollout_length, GAUSSIAN_MIXTURES,Z_DIM])\n",
    "\n",
    "    oneDivSqrtTwoPI = 1 / math.sqrt(2*math.pi)\n",
    "    result = y_true - mu\n",
    "#   result = K.permute_dimensions(result, [2,1,0])\n",
    "    result = result * (1 / (sigma + 1e-8))\n",
    "    result = -K.square(result)/2\n",
    "    result = K.exp(result) * (1/(sigma + 1e-8))*oneDivSqrtTwoPI\n",
    "    result = result * pi\n",
    "    result = K.sum(result, axis=2) #### sum over gaussians\n",
    "    #result = K.prod(result, axis=2) #### multiply over latent dims\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def rnn_r_loss(y_true, y_pred):\n",
    "\n",
    "    pi, mu, sigma = get_mixture_coef(y_pred)\n",
    "\n",
    "    result = tf_normal(y_true, mu, sigma, pi)\n",
    "\n",
    "    result = -K.log(result + 1e-8)\n",
    "    result = K.mean(result, axis = (1,2)) # mean over rollout length and z dim\n",
    "\n",
    "    return result\n",
    "\n",
    "def rnn_kl_loss(y_true, y_pred):\n",
    "    pi, mu, sigma = get_mixture_coef(y_pred)\n",
    "    kl_loss = - 0.5 * K.mean(1 + K.log(K.square(sigma)) - K.square(mu) - K.square(sigma), axis = [1,2,3])\n",
    "\n",
    "    return kl_loss\n",
    "\n",
    "def rnn_loss(y_true, y_pred):\n",
    "    return rnn_r_loss(y_true, y_pred) + rnn_kl_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(loss=rnn_loss, optimizer='rmsprop', metrics = [rnn_r_loss, rnn_kl_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = K.variable(rnn.predict(rnn_input[:5]))\n",
    "# y_true = K.variable(rnn_output[:5,:,:])\n",
    "\n",
    "# pi, mu, sigma = get_mixture_coef(y_pred, gaussian_mixtures, z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pi.shape)\n",
    "# print(mu.shape)\n",
    "# print(sigma.shape)\n",
    "# print(preds.shape)\n",
    "# print(rnn_input.shape)\n",
    "# print(rnn_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - 9s 21ms/step - loss: 0.3525 - val_loss: -2.0844\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 8s 19ms/step - loss: -2.3482 - val_loss: -2.5542\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.6006 - val_loss: -2.6870\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 7s 16ms/step - loss: -2.6850 - val_loss: -2.7463\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.7251 - val_loss: -2.7333\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 7s 16ms/step - loss: -2.7388 - val_loss: -2.7501\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.7627 - val_loss: -2.7729\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.7661 - val_loss: -2.7725\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 7s 18ms/step - loss: -2.7778 - val_loss: -2.7810\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.7811 - val_loss: -2.7702\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.7869 - val_loss: -2.7951\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.7876 - val_loss: -2.8085\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 7s 16ms/step - loss: -2.7959 - val_loss: -2.7939\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 7s 18ms/step - loss: -2.7952 - val_loss: -2.8075\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 7s 18ms/step - loss: -2.7998 - val_loss: -2.7982\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 7s 18ms/step - loss: -2.8011 - val_loss: -2.7972\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 7s 17ms/step - loss: -2.8027 - val_loss: -2.8050\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d6bd3cc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(rnn_input, rnn_output,\n",
    "        shuffle=True,\n",
    "        epochs=mdn_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.save_weights('./archive/models/rnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_model('./models/rnn.h5', custom_objects={'loss': rnn_loss(gaussian_mixtures,z_dim )})\n",
    "rnn.load_weights('./rnn/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = rnn.predict(np.array([rnn_input[0]]))\n",
    "# preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_action_from_controller(controller, z, h):\n",
    "    W_size = (z_dim+lstm_hidden_units) * action_dim\n",
    "    \n",
    "    W = controller[:W_size]\n",
    "    b = controller[W_size:]\n",
    "\n",
    "    W = W.reshape((z_dim+lstm_hidden_units, action_dim ))\n",
    "\n",
    "    x = np.concatenate([z,h])\n",
    "\n",
    "    a = np.matmul(x, W) + b\n",
    "    a = np.tanh(a)\n",
    "    a[1] = (a[1] + 1) / 2\n",
    "    a[2] = (a[2] + 1) / 2\n",
    "\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "\n",
    "def rollout(controller, video = False):\n",
    "\n",
    "    rollout_reward = 0\n",
    "\n",
    "    for sim in range(AGENT_ROLLOUTS):\n",
    "\n",
    "        obs = env.reset()\n",
    "        obs = obs.astype('float32') / 255.\n",
    "        env.render()\n",
    "\n",
    "        h = np.zeros(256)\n",
    "        c = np.zeros(256)\n",
    "        done = False\n",
    "        t = 0\n",
    "        cumulative_reward = 0\n",
    "        a = np.array([0,1,0])\n",
    "\n",
    "        while not done:\n",
    "        # while not done: #t < 600 and \n",
    "        #while t < 72:\n",
    "            if video:\n",
    "                display.clear_output(wait=True)\n",
    "                plt.figure(1, figsize=(20,10))\n",
    "\n",
    "                #plt.subplot(1, gaussian_mixtures + 1, 1)\n",
    "                plt.subplot(1, 1 + 1, 1)\n",
    "                plt.imshow(obs)\n",
    "\n",
    "            z = vae_encoder.predict(np.array([obs]))[0]\n",
    "\n",
    "            #a = pick_random_action(t, a)\n",
    "            a = pick_action_from_controller(controller,z,h)\n",
    "            #print(a)\n",
    "\n",
    "            obs, reward, done, _ = env.step(a)\n",
    "            \n",
    "            obs = obs.astype('float32') / 255.\n",
    "        #    reward = - reward\n",
    "        #     reward = 0\n",
    "\n",
    "            cumulative_reward += reward\n",
    "\n",
    "            input_to_rnn = [np.array([[np.concatenate([z, a])]]),np.array([h]),np.array([c])]\n",
    "            h, c = rnn_inference.predict(input_to_rnn)\n",
    "            h = h[0]\n",
    "            c = c[0]\n",
    "         #   \n",
    "\n",
    "        #   obs = z_decoded\n",
    "\n",
    "            if video: #and t > 70\n",
    "#                 input_to_rnn = [np.array([[np.concatenate([z, a])]])]\n",
    "#                 y_pred = rnn.predict(input_to_rnn)\n",
    "                \n",
    "#                 pi, mu, sigma = get_mixture_coef(y_pred)\n",
    "                \n",
    "#                 for g in range(gaussian_mixtures):\n",
    "                    \n",
    "#                     input_to_vae = mu[0,0,g,:].eval(session = sess)\n",
    "#                     print('Gaussian ' + str(g))\n",
    "#                     print('pi')\n",
    "#                     print(np.round(pi[0,0,g,:].eval(session = sess),3))\n",
    "#                     print('sigma')\n",
    "#                     print(np.round(sigma[0,0,g,:].eval(session = sess),3))\n",
    "#                     print('mu')\n",
    "#                     print(np.round(input_to_vae,3))\n",
    "#                     print('z')\n",
    "#                     print(np.round(z,3))\n",
    "#                     print('-------')\n",
    "#                     z_decoded = vae_decoder.predict(np.array([input_to_vae]))[0]\n",
    "\n",
    "#                    # plt.subplot(1, gaussian_mixtures + 1, g + 2)\n",
    "#                     plt.subplot(1, 1 + 1, g + 2)\n",
    "#                     plt.imshow(z_decoded)\n",
    "                \n",
    "                \n",
    "                z_decoded = vae_decoder.predict(np.array([z]))[0]\n",
    "                plt.subplot(1, 1 + 1, 2)\n",
    "                plt.imshow(z_decoded)\n",
    "                plt.show()\n",
    "                \n",
    "                #print(np.round(np.mean(pi.eval(session = sess),axis = 3),3))\n",
    "                \n",
    "                \n",
    "                print(t)\n",
    "                print(np.round(a,2))\n",
    "                print(np.round(reward,2))\n",
    "                print(np.round(cumulative_reward,2))\n",
    "\n",
    "            t = t + 1\n",
    "        \n",
    "        rollout_reward += cumulative_reward\n",
    "    \n",
    "    return (rollout_reward / AGENT_ROLLOUTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/CMA-ES/pycma/blob/master/cma/fitness_functions.py\n",
    "def fit_func(controller, video = False):\n",
    "    reward = rollout(controller, video = video) \n",
    "    return reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controller = np.random.uniform(-0.1,0.1,NPARAMS) # 100-dimensional problem\n",
    "# print(\"This is F(0):\")\n",
    "# print(cma_function(controller))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "    history = []\n",
    "    worst = []\n",
    "    best = []\n",
    "    av = []\n",
    "    for j in range(MAX_ITERATION):\n",
    "        print(\"Iteration\", j)\n",
    "        solutions = solver.ask()\n",
    "        fitness_list = np.zeros(solver.popsize)\n",
    "        for i in range(solver.popsize):\n",
    "            fitness_list[i] = fit_func(solutions[i])\n",
    "            print(' agent', i, 'scored', np.round(fitness_list[i],2))\n",
    "        solver.tell(fitness_list)\n",
    "        result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "        history.append(result[1])\n",
    "        best.append(np.max(fitness_list))\n",
    "        worst.append(np.min(fitness_list))\n",
    "        av.append(np.mean(fitness_list))\n",
    "        #if (j+1) % 100 == 0:\n",
    "        # print(\"Weights at iteration\", j, result[0])\n",
    "        print(\"Fitness at iteration\", j, np.round(result[1],2))\n",
    "        \n",
    "        pk.dump(solver, open('./archive/models/cmaes.pk', 'wb'))\n",
    "        #fit_func(result[0], video = True)\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        plt.figure(2)\n",
    "        plt.plot(history)\n",
    "        plt.plot(best)\n",
    "        plt.plot(worst)\n",
    "        plt.plot(av)\n",
    "        plt.show()\n",
    "        \n",
    "    print(\"Local optimum discovered by solver:\\n\", result[0])\n",
    "    print(\"Fitness score at this local optimum:\", result[1])\n",
    "    return history, worst ,av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYXFWd//H3t7qqeklIAtlTnSYJZDEBDaQNm/MTFAGDkoA4v7iMuIxxCcIsbugMEDWjz7jMwPCb0ajMDOMMERVJBgKMYVTkgQAdQNYEYxbozsqShU66a/v+/ri3qqs63elOOtVV3f15PU89XfeeU7fOocL53nvOueeauyMiIkNbpNwFEBGR8lMwEBERBQMREVEwEBERFAxERAQFAxERQcFARERQMBARERQMREQEiJa7AL01ZswYnzJlSrmLISIyYKxfv/4Vdx/bm7wDJhhMmTKFpqamchdDRGTAMLNtvc2rbiIREVEwEBERBQMREUHBQEREUDAQEREUDEREBAUDERFhAN1nIJUlk07T3tZKsu0QyfZDpNoPkmo/RKr9EJnc39QhsslDZFNtZFNteKoNTx3C0+20Ww1bRp3L63VTyl0VkYpWVx3l028/peTfU7JgYGZfBxYCWWA38FF3325mBtwELAAOhvufKFU5BivPZkmlkrS3HSTZlmuIw79tB0kn28gkD5EpaIyzyUN4OmiUSbdDuh3LtBFJt2GZdiKZdiLZJFXZdqLZJNFsO7FskqgniXmSOEningr+WoY6oK4PdTiff2RzdiL/k23kV9l5POWnktXFqkiRMcOr+yUYmLuX5sBmI9x9f/j+GmC2u3/azBYAnyMIBmcBN7n7WT0dr7Gx0SvtDuRsJkOy/RDtbUED3N52kHT7QVLJQ6TbD5FOHiKTbCObCs6Ws6m2fGPs6aBBtnRb8Mo1xpmgMS5skHONcSzXEHuKapJUWd9+u3aP0W4xksRJESMViZOyOGmrJh2Jk4lUk4nEyVZV518ercGrqiFag0WrIVaDRWuIxGuJxGqpiteEr1qi8Vpi1TXEqocRq6klXl1HvKaW6po6ogf3wMY1sOEe2Po7yKZh2FiYcQnMeg9MezvEao/TLyUyNJnZendv7E3ekl0Z5AJBaBiQa7kWArd5EIXWmdkoM5vo7jtKUY5nHlxFpr017LJoyzfI5BvkNizdXtAYB6+iBjnXGGdzZ8dJqkkRtzQ1QM0xli3rRhtxkrkG2WKkrDpokCPBqz16AplIQWOca5Cj1RCtxqI1WKyWSKwGiwUNca5RjsbriFbXEquuJVZdR7y6llhNHdU1tcSra6muqqL6eP7HPhojEzD/k8GrbR/84VdBYHh+FTz5HxCrg1PeAbMuDQJE3UnlKqnIkFDSMQMzWw58BNgHXBDuTgAvF2RrDveVJBic8sAnqbP2btOTXkUy3yBXhw1yrjGupj06nIO5xjhSTTYaNshVNRCthlgtFq3GYjVECl7ReC1V1UFj3HGGXEesupbq2mHB2XE0Rl0k0qeulkGhZiScfmXwSieDK4WNa2DDGthwN1gEGs6FWQtg5gI4aWq5Sywy6PSpm8jM1gITukj6qruvKsh3HVDj7jeY2d3At9z9oTDtAeBL7n5YH5CZLQGWADQ0NMzbtq3Xay7lbWh6gKpoPDw7riVeM4x4dS3xmuBMuSqqMfSK5Q7bn+wIDLufC/aPm9MRGCadAWblLadIhTqabqKSjRkUfYlZA7DG3U8zsx8Av3H328O0jcD5PXUTVeKYgfSz17Z0BIaXHgbPwogEzHx3EBim/AlE4+UupUjFqIgxAzOb7u5/CDcXAhvC96uBq81sJcEA8r5SjRfIIHPSVDhnafBqfRX+cH8wzvDUf8HjP4LqETD9XUFgmP6uoPtJRHqllH0k3zKzmQRTS7cBnw73ryGYSbSJYGrpx0pYBhmsho2GuR8MXqlDsPk3QWB48T549hcQicGUtwUD0DMXBAPWItKtfukmOh7UTSS9ks1Ac1Mw8LxxDby6Kdg/cW4QGGZdCuNma5xBBo5sFiLHdv9NxY0ZHA8KBnJM9rwIG+8JrhqaHw/2jTq5IzBMPhuqNIlAKoQ7vLYZWtYHJzUtTZBqg88+fEyHq4gxA5GKMHZG8HrbX8KBXfDivUFgePzHsO6fofbE4D6GmQvg1HdCfFi5SyxDycHXoOWJoNFvbgqCwKHXgrTYsGC23JQ/6dPVQW/pykCGpvY34I8PBDOTXrwP2vZCtAamnR8EhpnvhuHjyl1KGUzSSdj1DDSv72j8X/tjmGgw7k2QmAf1jZBohLGz+nzVqm4ikaORScFLjwSBYeM9sPclwGDy/CAwzLoUxkwvdyllIHGH17cWd/fseBoy4Q2wwyeEjX7Y+E86A6pPOO7FUDAQOVbusOvZjsCw4/fB/tHTO8YZEo0lv2SXAebQXtj+RHDW3/x4EAQOvhKkRWth0tyOhr/+rcH9Mf0wiUHBQOR42fsybLw3CAxbHwoX1BsHM8MF9aa+HWLHujqVDEiZFOx6LuzqCbt8XnmxI33MzOKz/nGzoSpWlqIqGIiUwqG9wYJ6G++BP6yF5IFgkO/UdwSBYfpFWlBvsHGHfS93DO42N8GOpyDdFqQPGxtcKdbPC/4mzqyomx0VDERKLd0eLKi34Z7gyuHADrAqOPnccJxhAZw4pdyllKPVtj/s7ilo/Ft3B2nRGpj4luLGf1RDRd+zomAg0p+yWdjxZBAYNqyBPS8E+8ef1hEYJs6t6EZjSMqkYffzxd09ezaSX21/9Klhwx++xp9Wtu6eY6VgIFJOr20Ol9++B15eFy6oVx9MV521AE5+mxbUK4d9LeHgbtj473gKUgeDtNqTOqZ01s8L+vtrTyxveY8DBQORStH6Crx4f7A0xqYHIH0IqkcGC+nNWgCnvgtqRpS7lINP+xvB8ueFN3MdCNfDrIrDhDcXN/4nTh2UV266A1mkUgwbA2d8KHglDwYL6m0Mxxme/XmwoN7U/9PxfIYRk8pd4oEnm4E9Gzrm8zevD7rqPBuknzQtuIs31/hPOC14MJUU0ZWBSDlkM/DyYx3rJr22Odg/6YxwpdVLgztSB+HZap/t31F8xr/9SUi+EaTVjCo44w+ndw7hGV7qJhIZSNyDgcuN4QB0S/jv/MQpQVCYdSlMPmtoLqiXbIXtTxU3/vtbgrRILDjLT4Q3ctU3BlcBCqB5CgYiA9n+HeGCemtgy28hkwwGOGdcEnQnnfKOwbmgXjYb3LzV0hQM9DavD2b7eCZIH3Vy8Vn/hDfrhr8eKBiIDBbtB4KB5w33BE92a9sXLqh3QRAYZrwbho8tdymPzRu7C/r5m4Lunvb9QVr1yOAGrlzjn5g3cOtZRhU1gGxmfw18Bxjr7q+YmQE3ETzt7CDwUXd/otTlEBmQqk+AOYuCVyYF2x4Ob3RbE1w9YEEX0qwFQZfSmFPLXeKupQ4F6zwVDvLueylIi0Rh/Bw4/f0djf/oU7X+Uz8r6ZWBmU0GfgTMAuaFwWAB8DmCYHAWcJO7n9XTsXRlIFLAHXY+EwSFDXcH7yFYFycXGBLzytOgZrPBE+by/fxNwVo+2XSQPrKh4w7e+sbgrt5Ybf+XcwiomG4iM/s58HVgFdAYBoMfAL9x99vDPBuB8919x5GOpWAgcgR7Xwqmq24IF9TzDAwfH9zoNvPSYPpqqfrXW1/p1N3zRNCdBRA/ARJndAzyJubBCeNLUw45TEV0E5nZQqDF3X9vxaP7CeDlgu3mcN9hwcDMlgBLABoaGkpVVJGBb1QDnPWp4HXo9WBBvQ33wDM/h/X/Fi6o985gZlJfFtRLtQVXIbmGv/lx2LstSLMIjJsDcy7vOOsfMwMiVcetmlI6fQoGZrYWmNBF0leBrwAX9eX47r4CWAHBlUFfjiUyZNSeCG/+0+CVboctD3YsqPfC6o4F9WZdGtzoduLJXR8n9zzewrP+nc9ANhWkj0gEZ/pv/UTQ+E+aOzhnOQ0RJekmMrPTgQcIBogB6oHtwHxgGeomEul/2WzQhZMbgN6zIdg//vRgnGH6xcHzd3ONf8v64CoDgiuLxJnFj2UcMbF8dZFeqZgxg/yXmG2lY8zgUuBqOgaQb3b3+T0dQ8FA5Dh79Y8dgeGldeRX6yx6Hm94M9fYWeruGYAqYszgCNYQBIJNBFcOHytDGURk9Clw3jXB6409wQ1uw8eV7Hm8Utn6JRi4+5SC9w4s7Y/vFZFeGj4WTr+y3KWQMtJdHSIiomAgIiIKBiIigoKBiIigYCAiIigYiIgICgYiIoKCgYiIoGAgIiIoGIiICAoGIiKCgoGIiKBgICIiKBiIiAgKBiIiQgmDgZndaGYtZvZU+FpQkHadmW0ys41mdnGpyiAiIr1T6ofb/IO7f6dwh5nNBhYDc4BJwFozm+HumRKXRUREulGObqKFwEp3b3f3LQSPv+zxGcgiIlI6pQ4GV5vZ02Z2q5mdGO5LAC8X5GkO94mISJn0KRiY2Voze7aL10LgX4BTgLnADuC7x3D8JWbWZGZNe/bs6UtRRUTkCPo0ZuDuF/Ymn5n9ELg73GwBJhck14f7ujr+CmAFQGNjox97SUVE5EhKOZtoYsHm5cCz4fvVwGIzqzazqcB04LFSlUNERHpWytlEf29mcwEHtgKfAnD358zsDuB5IA0s1UwiEZHyKlkwcPc/O0LacmB5qb5bRESOju5AFhERBQMREVEwEBERFAxERAQFAxERQcFARERQMBARERQMREQEBQMREUHBQEREUDAQEREUDEREBAUDERFBwUBERCjt8wxERKSX3J3s/v0km5tJtbSQam4h1dKCZ9JMvPHGkn+/goGISD/JvNFKqiXX2Ad/k2Gjn2puJvvGG0X5I8OHU33qqf1StpIGAzP7HLAUyAD3uPsXw/3XAZ8I91/j7veXshwiIv0he+hQ0LC3tIRn+NvzjX6quZnMvn1F+a22lnh9gtikBHXz5hGrryeWmES8vp5YIkHVyJH9VvaSBQMzuwBYCLzF3dvNbFy4fzawGJgDTALWmtkMPfpSRCpdNpkkvX170dl8qqWFZEvQ8GdeeaUov8XjxBIJYokENaefRiyRyDf0sfp6qk48ETMrU22KlfLK4DPAt9y9HcDdd4f7FwIrw/1bzGwTMB94pIRlERHpkadSpHbtKujCKe6/T+/eDe4dH4hGiU2aRCwxiRMuOD9s+HONfYLomDFYZGDM0yllMJgB/ImZLQfagM+7++NAAlhXkK853HcYM1sCLAFoaGgoYVFFZCjwTIb07t2kmptJFjTy+a6cXbsgU9BJEYkQnTCeeKKeYeecE3bjJIKunfp6ouPGYVVV5avQcdSnYGBma4EJXSR9NTz2ScDZwFuBO8xs2tEc391XACsAGhsbvYfsIjLEuTvpPXuKzuZTLc0d/fc7dkAqVfSZ6LhxxOrrqZ03jxH1CeJhF04skSA2YQIWi5WpNv2rT8HA3S/sLs3MPgPc6e4OPGZmWWAM0AJMLshaH+4TETkidyfz+uudZuMUDNRu3463txd9pmr0aGL1CWpPm8OIiy/O99fHEpOITZpEpLq6TLWpLKXsJroLuAD4tZnNAOLAK8Bq4L/M7HsEA8jTgcdKWA4RGUAy+/Z1PRunpZlky3b84MGi/FUjRxJLJKiePp3h559PrD7RMVA7aRKRuroy1WRgKWUwuBW41cyeBZLAVeFVwnNmdgfwPJAGlmomkcjQEcy173o2Tqq5meyBA0X5I8OGBWfyDSdTd845RbNxYokEVcOHl6kmg0vJgoG7J4EPd5O2HFhequ8WkfLJtrV1mmtfPFCb2bu3KL/V1OTP5uvOOKOjoQ/77yMjR1bM9MvBTHcgi8hRyc+172I2TrKl5fC59rFYx1z7OXM6ZuPk5tqfdJIa+wqgYCAiRTydJrVzV1FffX7ZhObmrufaT5xILJFg+PlvL56Nk6gnOnbgzLUfygZ9MNj+pS/jqRSYQSQCBmaR4u1IBPL7LDhL6Wq7MD/W9faRPp/b7urz+TzdlCf/mYJtO9Lnc2U+0ucNzDp93rCIdfz3IdwuzF/0+QhmhHUvyF+Qx6xwO8xvhmcdPAvZLLjj7sH7bDZIo2DbO70Ptz38bP4YBccM0ijYLkhzh3Dbs9n8++AY2eK0zsfIZoO0ro6RzQJdHCMblrnT9+WPkTtmtqAu3nHM/PvOx8h/31Eeo3A7lzc3B3/nzuK59mZEJ0wgnkgw7OyzOxr6sBsnOn48Fh30TcmgN+h/wbYXX8QPHQr+4TvF/5N03i74HyXfOHXe7iat6ExJpLfCIJoPsIUBtDAtv23ByUzuPdbNMSjI17tjWDRK7RlnMKJwNk5urn08Xu7/UlJigz4YTPvlnf32XYVnr90Gk8IzWig4oy04A82fuXX6fOHZcuFZ8NF83gs/0+lMM5c/f7zwrJVcmbv/fNEZNZ0+n/uOgjNp3CFSdfiVV9GVk3VcJUUiHVccFumUVniFU5gWXrlECq5KOl+15BvPgquqwrTOx+jcsHZKA4qOWfh9XTb4IhVi0AeD/mRmUFUVvAD9ry4iA4VGdURERMFAREQUDEREBAUDERFBwUBERFAwEBERFAxERAQFAxERQcFAREQoYTAws5+a2VPha6uZPVWQdp2ZbTKzjWZ2canKICIivVPKh9v839x7M/susC98PxtYDMwheOzlWjOboaediYiUT8m7iSxYjetPgdvDXQuBle7e7u5bgE3A/FKXQ0REutcfYwZ/Auxy9z+E2wng5YL05nCfiIiUSZ+6icxsLTChi6Svuvuq8P0H6LgqONrjLwGWADQ0NBxTGUVEpGd9CgbufuGR0s0sClwBzCvY3QJMLtiuD/d1dfwVwAqAxsZGPT1GRKRESt1NdCGwwd2bC/atBhabWbWZTQWmA4+VuBwiInIEpX64zWI6dRG5+3NmdgfwPJAGlmomkYhIeZU0GLj7R7vZvxxYXsrvFhGR3tMdyCIiomAgIiIKBiIigoKBiIigYCAiIigYiIgICgYiIoKCgYiIoGAgIiIoGIiICAoGIiKCgoGIiKBgICIiKBiIiAgKBiIigoKBiIhQwmBgZnPNbJ2ZPWVmTWY2P9xvZnazmW0ys6fN7MxSlUFERHqnlFcGfw8sc/e5wPXhNsC7CZ57PB1YAvxLCcsgIiK9UMpg4MCI8P1IYHv4fiFwmwfWAaPMbGIJyyEiIj0o5TOQ/wK438y+QxB0zg33J4CXC/I1h/t2dD6AmS0huHqgoaGhhEUVERna+hQMzGwtMKGLpK8C7wT+0t1/YWZ/CvwYuPBoju/uK4AVAI2Njd6XsoqISPf6FAzcvdvG3cxuA64NN38G/Ch83wJMLshaH+4TEZEyKeWYwXbg7eH7dwB/CN+vBj4Szio6G9jn7od1EYmISP8p5ZjBJ4GbzCwKtBH2/QNrgAXAJuAg8LESlkFERHqhZMHA3R8C5nWx34GlpfpekaHG3cl4hmQmSSqbIplJkswmSWVSXf4tTM/nzyRxnHc0vIPJJ0zu+Utl0CnllYHIoJPJZoIGNGxUu2pocw1s54a5cDvXAKez6aLtVLa4gU5mw32ZVNF24XfnGvLj4ZYnb+HqM67mQ2/6ENGImoehRL+2VKSsZw9rVPMNb+fGsouGNt+Adncm3E2+wxryTg10xjPHrY4RixCPxIlVxYhFYsSr4sQjceJVcWKRGLGqGPFInOGx4cSre86X2y78m38ffk/us53TY1UxDiQP8K3HvsV3mr7DfVvuY9l5y5hx4ozjVl+pbBb02lS+xsZGb2pqKncx5BgcTB1ky74tbN63mS37trBl3xZ2tu6kPdt+WAOda5jT2fRxLUOuscw3fgWNYTwSJxqJFm33puE9Ur54VTyf97CGOfxbiWfe7s792+7nm49+k/3t+/nE6Z9gyZuXEK+Kl7tocgzMbL27N/Ymb+X9a5QByd155dArRY1+7u+ug7vy+aqsisknTCYxPEF1VfURG+i+ngnnGuSoRTGzMv7XGTjMjEumXMLZE87m203f5gdP/4BfbfsVy85dxtxxc8tdPCkhXRnIUUln0zQfaD7sTH/Lvi0cSB3I56uL1jF15FSmjZxW9HfyCZOJVcXKWAM5Gg+1PMTXHvkaO1t38oFZH+DaM6+lLlZX7mJJLx3NlYGCgXTpYOogW/YHjfzmvZvZun8rm/duZtuBbUVdOGNrxzJt5DSmjJxS1OiPrxuvs/FBojXVyk1P3MTKDSuZOGwi159zPeclzit3saQXFAykV9ydV9tezZ/ZF3bv7Gzdmc+X69qZOnJqUYM/deRUToifUMYaSH96avdTXP/w9WzZt4XLTrmML771i4ysHlnuYskRKBhIkXQ2zfY3th/Wl79532YOJDu6dmqjtV127TSc0KCuHQGgPdPOiqdXcOsztzKiegRfOesrXHTyRboKrFAKBkPUwdRBtu7felh//rb920hlU/l8Y2rHHHaGP23kNHXtSK9tfG0j1z98Pc+/+jwXTL6Avzn7bxhXN67cxZJOFAwGMXfntbbXDhu83bxvMztaO5Z4ilikqGtn6oipTBs1jSkjpujSXo6LdDbNT57/Cbc8dQvxSJy/bvxrrph+hU4oKoiCwSCQyWa67drZn9yfz1cbrWXKiClMGzUt3+BPHTGVhhENmhsu/eKl/S9x4yM38vjOx5k/YT43nHMDDSP0/JFKoGAwgBxKH2Lb/m1s3ruZLfu35P9u27eNZDaZzze6ZnSX/fnjh40nYqVcfFakZ+7OL/7wC77b9F3S2TRL5y7lw7M/XJE31g0lCgYVxt15vf31wxr8LXu3sL11ez5fxCLUD68/rD9/6sip6tqRAWFX6y6+8eg3+M3Lv2HO6DksO3cZM0+aWe5iDVkKBmWSyWbY3rq9y6ma+9r35fPVVNUUNfT5WTsjGqiuqi5jDUT6rvOSFh8//eN86s2fUrdlGSgYlFhbui3o2unUn79t/zbaM+35fCfVnNRl186EYRPUtSOD3t62vXy76dus/uNqpo2cpiUtyqAigoGZvQX4PjAc2Ap8yN33h2nXAZ8AMsA17n5/T8crRzB4ve31olk7uffb39ieXzI4YhESwxNdNvrq2hHRkhblVCnB4HHg8+7+WzP7ODDV3f/WzGYDtwPzgUnAWmCG+5HXBi5VMMh6tmjWTmHDv7d9bz5fTVVNsOTCiKlMHdXRvXPyiJPVtSPSg9ZUKzc/cTO3b7hdS1r0o0oJBvuAUe7uZjYZuN/dZ4dXBbj7N8N89wM3uvsjRzpeX4NBrmun81n+1v1bD+vaOWyq5sipTBw2UV07In3UeUmLLzR+gVE1o8pdrEGrUpawfg5YCNwFvB/IPUsvAawryNcc7jvu0tk01/76Wjbv3UzLGy35rh3D8l07Z088OzjLDxt//cMUKZ254+by8/f+nBVPr+DHz/yYh1oe4rqzruPiky/WzWpl1qdgYGZrgQldJH0V+Dhws5n9LbAaSHaRr6fjLwGWADQ0HP1NLNFIlGQmyWljTuOyUy7Lz945ecTJ1ERrjvp4ItJ38ao4V59xNe86+V3c8PANfOG3X2DN5DVa0qLM+mU2kZnNAH7i7vPL1U0kIpUnnU3zny/8J7c8eQuxSIy/avwr3jf9fbpKOE6OppuoZJ3gZjYu/BsB/oZgZhEEVwmLzazazKYC04HHSlUOEalc0UiUq+ZcxS8u+wWzRs9i2SPL+PP/+XNe2v9SuYs25JRyRPQDZvYisAHYDvwrgLs/B9wBPA/cByztaSaRiAxuDSMa+PFFP+aGc27g+Vef54rVV/Bvz/7bcX8WtnRPN52JSEXZ1bqL5Y8u59cv/1pLWvRRRXQTiYgci/HDxnPTBTfxnbd/hx2tO1h892L+6cl/Ipk56jkochQUDESk4pgZF0+5mFULV7Fg2gJWPL2CK//7Sp7c/WS5izZoKRiISMUaVTOK5W9bzvcv/D5t6TauuvcqvvnoNzmYOljuog06CgYiUvHOS5zHXQvv4oNv+iC3b7idRasW8VDLQ+Uu1qCiYCAiA0JdrI4vz/8yt737NmqiNXxm7Wf4yu++wt62vT1/WHqkYCAiA0puSYtPvflT3LvlXhauWsh9W+9joMyMrFQKBiIy4OSWtFj5npVMHDaRL/z2C1zz62vY1bqr3EUbsBQMRGTAmnnSTH6y4Cd8vvHzrNu+jkWrFvGzF39G1rPlLtqAo2AgIgNabkmLOy+7k9mjZ/O1R76mJS2OgYKBiAwKk0dM5kcX/Ygbz7mRDa9u4IrVV/Cvz/6rlrToJQUDERk0zIz3zXgfdy26i/Mmncf31n+PD635EBtf21juolU8BQMRGXTG1Y3jHy/4R7779u+ys3Uni+9ezM1P3Fz0VEMppmAgIoOSmXHRlIvyS1r88Jkf8v7/fr+WtOiGgoGIDGqFS1q0p9u56t6r+LtH/47WVGu5i1ZRFAxEZEg4L3Eev1z4Sz74pg+ycsNKLl91uZa0KKBgICJDRuGSFrXRWi1pUaBPwcDM3m9mz5lZ1swaO6VdZ2abzGyjmV1csP+ScN8mM/tyX75fRORYzB03l5+992fFS1psGdpLWvT1yuBZ4ArgwcKdZjYbWAzMAS4B/tnMqsysCvh/wLuB2QSPxpzdxzKIiBy1w5a0eHBoL2nRp2Dg7i+4e1cTeBcCK9293d23AJuA+eFrk7tvdvcksDLMKyJSFlrSIlCqMYME8HLBdnO4r7v9XTKzJWbWZGZNe/bsKUlBRUS0pEUvgoGZrTWzZ7t4lfyM3t1XuHujuzeOHTu21F8nIkNcbkmLZecuG3JLWkR7yuDuFx7DcVuAyQXb9eE+jrBfRKTszIwrpl/B2xJvY/m65Xxv/fe4b+t9fO3crzHzpJnlLl7JlKqbaDWw2MyqzWwqMB14DHgcmG5mU80sTjDIvLpEZRAROWZDbUmLvk4tvdzMmoFzgHvM7H4Ad38OuAN4HrgPWOruGXdPA1cD9wMvAHeEeUVEKk5uSYvVi1Zz6bRL+eEzP+TK1VcOyiUtbKDMq21sbPSmpqZyF0NEhrCHWx5m2SPL2NG6g8WzFnPtmdcyLDas3MXqlpmtd/fGnnPqDmQRkV47N3Fu0ZIWi1Yt4nfNvyt3sY4LBQMRkaNQuKQBBqgwAAAG9ElEQVRFXbSOzz7wWa773XW83vZ6uYvWJwoGIiLHILekxaff8mnu23Ifi1YtGtBLWigYiIgco3hVnKVzl7LyPSuZNGxSsKTF/17Dztad5S7aUVMwEBHpo6IlLXas4/JVl3PHxjsG1JIWCgYiIsdBVaQqv6TFnNFz+Pq6r/OJ+z/Btv3byl20XlEwEBE5jiaPmMwPL/ohy85dxsbXNvK+1e/j1mdvrfglLRQMRESOs9ySFnctuovzJp3HP6z/Bz54zwfZ8NqGchetWwoGIiIlUrikxe6Duyt6SQsFAxGREsotabFq0SreM+09+SUtntj1RLmLVkTBQESkH4ysHsk33vYNfnDhD0hlU1x131UsX7ec1lRruYsGKBiIiPSrcxPncudld/LhN32Yn278KYtWLeLB5gd7/mCJKRiIiPSzulgdX5r/JW57920Miw5j6QNLy76khYKBiEiZzB03lzvee0fRkhb3brm3LEtaKBiIiJRRbkmLn773p0waNokvPvhFPve/n+v3JS36+nCb95vZc2aWNbPGgv2jzezXZvaGmd3S6TPzzOwZM9tkZjebmfWlDCIig8GME2fkl7R4dMejLFq1qF+XtOjrlcGzwBVA59GPNuBvgc938Zl/AT5J8CjM6cAlfSyDiMigkF/SYuGdnDb6tPySFgdTB0v+3dG+fNjdX4BgHm2n/a3AQ2Z2auF+M5sIjHD3deH2bcAi4N6+lENEZDCZfEKwpMUvN/2S3+/5PXWxupJ/Z5+CwTFIAM0F283hPhERKZBb0uKK6Vf0y/f1GAzMbC0woYukr7r7quNfpKLvXgIsAWhoaCjlV4mIDGk9BgN3v/A4fl8LUF+wXR/u6+67VwArABobGwfm44NERAaAfp1a6u47gP1mdnY4i+gjQEmvLkREpGd9nVp6uZk1A+cA95jZ/QVpW4HvAR81s2Yzmx0mfRb4EbAJ+CMaPBYRKbu+zib6JfDLbtKmdLO/CTitL98rIiLHl+5AFhERBQMREVEwEBERwMqxOt6xMLM9wLZj/PgY4JXjWJxyGix1GSz1ANWlEg2WekDf6nKyu4/tTcYBEwz6wsya3L2x55yVb7DUZbDUA1SXSjRY6gH9Vxd1E4mIiIKBiIgMnWCwotwFOI4GS10GSz1AdalEg6Ue0E91GRJjBiIicmRD5cpARESOYFAFAzO7xMw2ho/U/HIX6dVm9tMw/VEzm9L/pexZL+rxUTPbY2ZPha8/L0c5e2Jmt5rZbjN7tpt0Cx99usnMnjazM/u7jL3Vi7qcb2b7Cn6T6/u7jL1lZpPDx9I+Hz629tou8lT8b9PLegyI38XMaszsMTP7fViXZV3kKW375e6D4gVUESx8Nw2IA78HZnfK81ng++H7xcBPy13uY6zHR4Fbyl3WXtTl/wBnAs92k76AYKFCA84GHi13mftQl/OBu8tdzl7WZSJwZvj+BODFLv6NVfxv08t6DIjfJfzvPDx8HwMeBc7ulKek7ddgujKYD2xy983ungRWAgs75VkI/Hv4/ufAO63zMzvLrzf1GBDc/UHgtSNkWQjc5oF1wKjw0agVpxd1GTDcfYe7PxG+PwC8wOFPHKz436aX9RgQwv/Ob4SbsfDVeUC3pO3XYAoGCeDlgu2uHqmZz+PuaWAfMLpfStd7vakHwPvCy/efm9nk/inacdfbug4U54SX+fea2ZxyF6Y3wq6GMwjORAsNqN/mCPWAAfK7mFmVmT0F7AZ+5e7d/ialaL8GUzAYSv4bmOLubwZ+RcfZgpTPEwS3/r8F+CfgrjKXp0dmNhz4BfAX7r6/3OU5Vj3UY8D8Lu6ecfe5BE+AnG9m/brU/2AKBi1A4RlyV4/UzOcxsygwEni1X0rXez3Ww91fdff2cPNHwLx+Ktvx1pvfbEBw9/25y3x3XwPEzGxMmYvVLTOLETSg/+nud3aRZUD8Nj3VY6D9LgDuvhf4NXBJp6SStl+DKRg8Dkw3s6lmFicYYFndKc9q4Krw/ZXA/3o4GlNBeqxHp77bywj6Sgei1cBHwpkrZwP7PHg06oBjZhNy/bdmNp/g/61KO9EAgplCwI+BF9z9e91kq/jfpjf1GCi/i5mNNbNR4fta4F3Ahk7ZStp+9elJZ5XE3dNmdjVwP8GMnFvd/Tkz+xrQ5O6rCf7h/IeZbSIYDFxcvhJ3rZf1uMbMLgPSBPX4aNkKfARmdjvBbI4xFjwe9QaCgTHc/fvAGoJZK5uAg8DHylPSnvWiLlcCnzGzNHAIWFyBJxo55wF/BjwT9lEDfAVogAH12/SmHgPld5kI/LuZVREErDvc/e7+bL90B7KIiAyqbiIRETlGCgYiIqJgICIiCgYiIoKCgYiIoGAgIiIoGIiICAoGIiIC/H9x1qvlXelcJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4\n",
      " agent 0 scored -11.65\n",
      " agent 1 scored -74.26\n",
      " agent 2 scored -30.07\n",
      " agent 3 scored -67.03\n",
      " agent 4 scored -70.0\n",
      " agent 5 scored -64.16\n",
      " agent 6 scored -81.75\n",
      " agent 7 scored -62.59\n",
      " agent 8 scored -44.81\n",
      " agent 9 scored -79.93\n",
      " agent 10 scored -62.2\n",
      " agent 11 scored -57.89\n",
      " agent 12 scored -58.86\n",
      " agent 13 scored -72.48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-480c2ed0d737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0msigma_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcma_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-8e45ca052612>\u001b[0m in \u001b[0;36mtest_solver\u001b[0;34m(solver)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfitness_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mfitness_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' agent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scored'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-965e7f752773>\u001b[0m in \u001b[0;36mfit_func\u001b[0;34m(controller, video)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Rastrigin test objective function, shifted by 10. units away from origin\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-8cd287d32111>\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(controller, video)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m#a = pick_action(np.concatenate([z,h]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1835\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "cmaes = CMAES(NPARAMS,\n",
    "              popsize=NPOPULATION,\n",
    "              weight_decay=0.0,\n",
    "              sigma_init = 0.5\n",
    "          )\n",
    "cma_history = test_solver(cmaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      " agent 0 scored 7.43\n",
      " agent 1 scored 6.25\n",
      " agent 2 scored 7.32\n",
      " agent 3 scored 6.19\n",
      " agent 4 scored 7.29\n",
      " agent 5 scored 6.53\n",
      " agent 6 scored 7.4\n",
      " agent 7 scored 7.38\n",
      " agent 8 scored 6.31\n",
      " agent 9 scored 7.13\n",
      " agent 10 scored 6.27\n",
      " agent 11 scored 6.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-081abb811d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#cmaes = pk.load(open('./archive/models/cmaes.pk', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcmaes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./log/car_racing.cma.4.32.es.pk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcma_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-8e45ca052612>\u001b[0m in \u001b[0;36mtest_solver\u001b[0;34m(solver)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfitness_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mfitness_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' agent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scored'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-965e7f752773>\u001b[0m in \u001b[0;36mfit_func\u001b[0;34m(controller, video)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Rastrigin test objective function, shifted by 10. units away from origin\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-1c1bb5b2a254>\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(controller, video)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/ADSP/Public/AppliedDataSciencePartners/WorldModels/gym/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/ADSP/Public/AppliedDataSciencePartners/WorldModels/gym/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglViewport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_road\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0mgeom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/ADSP/Public/AppliedDataSciencePartners/WorldModels/gym/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mrender_road\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroad_poly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglColor4f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglVertex3f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "#cmaes = pk.load(open('./archive/models/cmaes.pk', 'rb'))  \n",
    "cmaes = pk.load(open('./log/car_racing.cma.4.32.es.pk', 'rb'))  \n",
    "cma_history = test_solver(cmaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fit_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9bb6aa342ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CarRacing-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcmaes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./controller/car_racing.cma.4.32.es.pk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmaes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_func' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "cmaes = pk.load(open('./controller/car_racing.cma.4.32.es.pk', 'rb'))  \n",
    "fit_func(cmaes.result()[0], video = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6c4450b377d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_decoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2213\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# if toolbar:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m#     toolbar.set_cursor(cursors.WAIT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1475\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2605\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1192\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1On\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0mextent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0mticklabelBoxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2On\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    298\u001b[0m         tmp, lp_h, lp_bl = renderer.get_text_width_height_descent('lp',\n\u001b[1;32m    299\u001b[0m                                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                                                          ismath=False)\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0moffsety\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_bl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/worldmodels/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "\n",
    "for sim in range(AGENT_ROLLOUTS):\n",
    "\n",
    "    obs = env.reset()\n",
    "    env.render()\n",
    "\n",
    "    h = np.zeros(256)\n",
    "    c = np.zeros(256)\n",
    "    done = False\n",
    "    cumulative_reward = 0\n",
    "    t = 0\n",
    "    a = np.array([0,1,0])\n",
    "\n",
    "    while not done:\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(obs)\n",
    "\n",
    "        z = vae_encoder.predict(np.array([obs]))[0]\n",
    "\n",
    "        a = pick_random_action(t,a)\n",
    "\n",
    "        obs, reward, done, _ = env.step(a)\n",
    "        obs = obs.astype('float32') / 255.\n",
    "    #     reward = 0\n",
    "\n",
    "        cumulative_reward += reward\n",
    "\n",
    "        input_to_rnn = [np.array([[np.concatenate([z, a])]]),np.array([h]),np.array([c])]\n",
    "        h, c = rnn_inference.predict(input_to_rnn)\n",
    "        h = h[0]\n",
    "        c = c[0]\n",
    "        z_decoded = vae_decoder.predict(np.array([z]))[0]\n",
    "\n",
    "    #     obs = z_decoded\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(z_decoded)\n",
    "        plt.show()\n",
    "\n",
    "        print(t)\n",
    "        print(a)\n",
    "\n",
    "        t = t + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldmodels",
   "language": "python",
   "name": "worldmodels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
